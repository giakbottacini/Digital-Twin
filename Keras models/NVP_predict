
import os

os.environ["KERAS_BACKEND"] = "tensorflow"

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import keras
from keras import regularizers
from keras import ops
from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_absolute_error
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow_probability as tfp
from keras import layers


# Specify the example you are dealing with
esempio = 'L_FRAME_DT'
# Training and Testing data
ID              = '7_1'
save_ID         = 'Classifier_total_7_1/'
path            = "../" + esempio + '/Dati/'
path_data_train   = path + 'istantrain_' + ID
path_data_test   = path + 'istantest_' + ID
# Saving model
path_save       = "models/"
# Prediction model
restore_ID= 'Classifier_total_7_1/'
path_restore = path + restore_ID
# Which dof monitored
which_channels = [1,2,3,4,5,6,7,8]

n_channels = 8
seq_len = 200
# Specify if you are using accelerations =1 or displacements =0
accelerations = 0

output_dir = "output_NVP"


"""
## Importazione dati
"""

# Read data and create dataset with only desired classes
def read_data(path_data):    
    label_path_class = path_data + '/Damage_class.csv'                                
    labels_class     = np.genfromtxt(label_path_class)
    labels_class     = labels_class.astype('int')
    N_ist = len(labels_class)  

    if accelerations == 1:
        path_rec  = path_data + '/U2_concat_'
    elif accelerations == 0:
        path_rec  = path_data + '/U_concat_'

    if path_data == path_data_train:
        signals_means = np.zeros((n_channels))
        signals_stds = np.zeros((n_channels))
    else:
        signals_means = np.load(path_restore+'/Corrupted_signals_means.npy')
        signals_stds = np.load(path_restore+'/Corrupted_signals_stds.npy')
    # Create the dataset output structure
    X       = np.zeros((N_ist, seq_len, n_channels))   #(10000,200,8)
    # X_noise = np.zeros((N_ist, seq_len, n_channels))
    for i1 in range(n_channels):
        path_data_var  = path_rec + str(which_channels[i1]) + '.csv'
        X_singledof = pd.read_csv(path_data_var, header=None).to_numpy()[:,0]
        for i2 in range(N_ist):
            # RESHAPE THE SIGNALS
            X[i2,:,i1]= X_singledof[1 + i2*(1+seq_len) : (i2+1)*(1+seq_len)]
            # # CORRUPT THE SIGNALS
            # rms_signal = RMS(X[i2,:,i1])
            # dev_std    = rms_signal / np.sqrt(addedd_SNR)
            # sample = st.norm(0, dev_std)
            # X_noise[i2,:,i1] = X[i2,:,i1] + sample.rvs(size=seq_len)
        if path_data == path_data_train:
            # COMPUTE STATISTICS FOR EACH CHANNEL
            # signals_means[i1] = np.mean(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            # signals_stds[i1] = np.std(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            signals_means[i1] = np.mean(np.reshape(X[:,:,i1], (N_ist*seq_len)))
            signals_stds[i1] = np.std(np.reshape(X[:,:,i1], (N_ist*seq_len)))

        # NORMALIZE THE SIGNALS    
        # X_noise[:,:,i1] = (X_noise[:,:,i1] - signals_means[i1])/signals_stds[i1]
        X[:,:,i1] = (X[:,:,i1] - signals_means[i1])/signals_stds[i1]
   
    # if path_data == path_data_train:    
    #     np.save(path_save+'Corrupted_signals_means', signals_means)
    #     np.save(path_save+'Corrupted_signals_stds', signals_stds)
       
    # return X_noise, labels_class, N_ist
    return X, labels_class, N_ist

    
    


"""
## Affine coupling layer
"""

# Creating a custom layer with keras API.
output_dim = 256  # Opzioni 256, 512, 1024
reg = 0.01

# Number of classes in the dataset
n_class = 8

seq_len = 200

# Hyperparameters
validation_split = 0.20
batch_size = 32
n_epochs = 250
early_stop_epochs=15
initial_lr = 1e-3
decay_length = 0.8
ratio_to_stop = 0.05

filter_1      = 32;   filter_2      = 64;   filter_3      = 32
kernel_size_1 = 25;   kernel_size_2 =  13;   kernel_size_3 = 7
neurons_4 = 64
neurons_5 = 16
attivaz_conv = 'tanh'
attivaz_mlp = 'tanh'
k_reg = 1e-3
b_reg = 1e-3
rate_drop = 0.05


def Coupling(input_shape=(200, 8), num_classes=n_class, reg=0.01):
    # Input con shape (200, 8), ovvero 200 time steps con 8 feature per step
    input_x = layers.Input(shape=input_shape, name='Input_X')
    input_y = layers.Input(shape=(num_classes,), name='Input_Label')
    
    # Network per condizionare s e t in funzione del label y
    # Uso un piccolo MLP per una rappresentazione più complessa dell'embedding delle classi
    label_condition = layers.Dense(64, activation='relu')(input_y)
    label_condition = layers.Dense(128, activation='relu')(label_condition)
    label_condition = layers.Dense(128, activation='relu')(label_condition)
    label_embedding = layers.Dense(256, activation='relu')(label_condition)  # Aggiungiamo un terzo livello per maggiore complessità

    # Blocchi convoluzionali per l'estrazione di caratteristiche temporali
    x = layers.Conv1D(filters=filter_1, kernel_size=kernel_size_1, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_1')(input_x)
    x = layers.MaxPooling1D()(x)
    x = layers.Conv1D(filters=filter_2, kernel_size=kernel_size_2, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_2')(x)
    x = layers.MaxPooling1D()(x)
    x = layers.Conv1D(filters=filter_3, kernel_size=kernel_size_3, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_3')(x)
    x = layers.MaxPooling1D()(x)
    x = layers.Flatten()(x)

    # Livelli densi per la componente t (traslazione) con condizionamento MLP
    t = keras.layers.Dense(128, activation="relu", kernel_regularizer=regularizers.l2(reg))(x)
    t_embedding = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(reg))(label_embedding)
    t = layers.Concatenate()([t, t_embedding])  # Condizionamento
    t = keras.layers.Dense(input_shape[0] * input_shape[1], activation="linear", kernel_regularizer=regularizers.l2(reg))(t)
    t_reshaped = keras.layers.Reshape(input_shape)(t)

    # Livelli densi per la componente s (scalatura) con condizionamento MLP
    s = keras.layers.Dense(128, activation="relu", kernel_regularizer=regularizers.l2(reg))(x)
    s_embedding = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(reg))(label_embedding)
    s = layers.Concatenate()([s, s_embedding])  # Condizionamento
    s = keras.layers.Dense(input_shape[0] * input_shape[1], activation="tanh", kernel_regularizer=regularizers.l2(reg))(s)
    s_reshaped = keras.layers.Reshape(input_shape)(s)

    return keras.Model(inputs=[input_x, input_y], outputs=[s_reshaped, t_reshaped])





# def Coupling(input_shape=(200, 8), num_classes=n_class, reg=0.01):
#     # Input con shape (200, 8), ovvero 200 time steps con 8 feature per step
#     input_x = layers.Input(shape=input_shape, name='Input_X')
#     input_y = layers.Input(shape=(num_classes,), name='Input_Label')
    
#     # Network per condizionare s e t in funzione del label y
#     # Utilizzo di una rete di embedding per ottenere una rappresentazione continua della classe
#     label_embedding = layers.Dense(64, activation='relu')(input_y)
#     label_embedding = layers.Dense(128, activation='relu')(label_embedding)
    
#     # Blocchi convoluzionali per l'estrazione di caratteristiche temporali
#     x = layers.Conv1D(filters=64, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(reg))(input_x)
#     x = layers.MaxPooling1D()(x)
#     x = layers.Conv1D(filters=128, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(reg))(x)
#     x = layers.MaxPooling1D()(x)
#     x = layers.Conv1D(filters=256, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(reg))(x)
#     x = layers.MaxPooling1D()(x)
#     x = layers.Flatten()(x)
    
#     # Livelli densi per la componente t (traslazione) con condizionamento moltiplicativo
#     t = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(reg))(x)
#     t_embedding = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(reg))(label_embedding)
#     t = layers.Concatenate()([t, t_embedding])
#     t = layers.Dense(input_shape[0] * input_shape[1], activation='linear', kernel_regularizer=regularizers.l2(reg))(t)
#     t_reshaped = layers.Reshape(input_shape)(t)

#     # Livelli densi per la componente s (scalatura) con condizionamento moltiplicativo
#     s = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(reg))(x)
#     s_embedding = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(reg))(label_embedding)
#     s = layers.Concatenate()([s, s_embedding])
#     s = layers.Dense(input_shape[0] * input_shape[1], activation='tanh', kernel_regularizer=regularizers.l2(reg))(s)
#     s_reshaped = layers.Reshape(input_shape)(s)

#     return keras.Model(inputs=[input_x, input_y], outputs=[s_reshaped, t_reshaped])


"""
## Real NVP
"""


class RealNVP(keras.Model):
    def __init__(self, num_coupling_layers, num_classes):
        super().__init__()

        self.num_coupling_layers = num_coupling_layers
        self.num_classes = num_classes

        # Distribuzione dello spazio latente (200, 8)
        self.distribution = tfp.distributions.MultivariateNormalDiag(
            loc=[0.0] * 1600, scale_diag=[1.0] * 1600  # La distribuzione ha 1600 dimensioni (200 * 8)
        )

        # Maschere (alterniamo metà delle dimensioni su entrambe le direzioni)
        self.masks = tf.convert_to_tensor(
            [[0] * 800 + [1] * 800, [1] * 800 + [0] * 800] * (num_coupling_layers // 2), dtype=tf.float32
        )

        self.loss_tracker = keras.metrics.Mean(name="loss")
        self.log_likelihood_tracker = keras.metrics.Mean(name="log_likelihood")
        self.log_det_inv_tracker = keras.metrics.Mean(name="log_det_inv")

        self.layers_list = [Coupling(input_shape=(200, 8), num_classes=num_classes) for i in range(num_coupling_layers)]
    
    @property
    def metrics(self):
        return [self.loss_tracker,
                self.log_likelihood_tracker,
                self.log_det_inv_tracker]

    def call(self, x, y, training=True):

        log_det_inv = 0
        direction = -1 if training else 1  # Direzione della trasformazione (invertito in training)

        for i in range(self.num_coupling_layers)[::direction]:
            # Separiamo x_A (parte trasformata) e x_B (parte invariata) tramite le maschere
            mask = tf.reshape(self.masks[i], [1, 200, 8])  # Aggiungi una dimensione batch

            mask = tf.tile(mask, [tf.shape(x)[0], 1, 1])  # Replica la maschera per il batch size

            x_A = x * mask  # Parte trasformata
            x_B = x * (1 - mask)  # Parte invariata
            
            # Passa x_B mascherato e il label y per calcolare s(x_B) e t(x_B)
            s, t = self.layers_list[i]([x_B, y])  # Funzioni di scalatura e traslazione
            
            # Applica la trasformazione diretta o inversa in base alla direzione
            if direction == 1:
                # In avanti: y_A = x_A * e^{s(x_B)} + t(x_B)
                x_A = x_A * tf.exp(s) + t
            else:
                # In inverso: x_A = (y_A - t(x_B)) / e^{s(x_B)}
                x_A = (x_A - t) / tf.exp(s)

            # Ricombina x_A trasformato con x_B invariato
            x = x_A * mask + x_B * (1 - mask)

            
            log_det_inv += tf.reduce_sum(s * mask, axis=[1, 2])  # Log-determinante su s(x_B)

        return x, log_det_inv
    

    def compute_loss(self, x, y):

        # Applica il modello per ottenere z_pred e il log-determinante del Jacobiano
        z_pred, log_det_inv = self(x, y)

        # Rimodella z_pred in (None, 1600) per farlo corrispondere alla dimensione della distribuzione
        z_pred = tf.reshape(z_pred, [-1, 1600])

        # Calcola la log-likelihood condizionata
        log_likelihood = self.distribution.log_prob(z_pred)

        # La funzione di perdita è la negativa della log-likelihood più il log_det_inv
        loss = -tf.reduce_mean(log_likelihood - log_det_inv)

        
        return loss, tf.reduce_mean(log_likelihood), tf.reduce_mean(log_det_inv)

    

    def train_step(self, data):
        x, y = data  # Estraiamo i dati e le etichette
        with tf.GradientTape() as tape:
            loss, log_likelihood, log_det_inv = self.compute_loss(x, y)

        # Calcola i gradienti
        grads = tape.gradient(loss, self.trainable_variables)
        # Applica i gradienti
        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))

        # Aggiorna lo stato del tracker della perdita
        self.loss_tracker.update_state(loss)
        # Aggiorna i tracker delle componenti
        self.log_likelihood_tracker.update_state(log_likelihood)
        self.log_det_inv_tracker.update_state(log_det_inv)

        return {
            "loss": self.loss_tracker.result(),
            "log_likelihood": self.log_likelihood_tracker.result(),
            "log_det_inv": self.log_det_inv_tracker.result(),
        }



    def test_step(self, data):
        x, y = data
        loss, log_likelihood, log_det_inv = self.compute_loss(x, y)
        self.loss_tracker.update_state(loss)

        self.log_likelihood_tracker.update_state(log_likelihood)
        self.log_det_inv_tracker.update_state(log_det_inv)
        
        return {
            "loss": self.loss_tracker.result(),
            "log_likelihood": self.log_likelihood_tracker.result(),
            "log_det_inv": self.log_det_inv_tracker.result(),
        }


    def predict(self, x, y):
        # Assicurati che x e y siano TensorFlow tensors
        x = tf.convert_to_tensor(x, dtype=tf.float32)
        y = tf.convert_to_tensor(y, dtype=tf.float32)

        # Applica il modello per ottenere z_pred e il log-determinante del Jacobiano
        z_pred, log_det_inv = self(x, y, training=False)

        # Rimodella z_pred in (None, 1600) per farlo corrispondere alla dimensione della distribuzione
        z_pred = tf.reshape(z_pred, [-1, 1600])

        # Calcola la log-likelihood condizionata
        log_likelihood = self.distribution.log_prob(z_pred) - log_det_inv

        return log_likelihood


    def predict_for_all_labels(self, x):
        # Assicurati che x sia un tensore
        x = tf.convert_to_tensor(x, dtype=tf.float32)
        
        # Creare un array one-hot per tutte le classi
        all_labels = np.eye(self.num_classes)  # (num_classes, num_classes)
        all_labels = tf.convert_to_tensor(all_labels, dtype=tf.float32)
        
        # Replica x per ogni label (batch_size, num_classes, features)
        x_expanded = tf.expand_dims(x, 1)  # Aggiungi una dimensione per i label: (batch_size, 1, features)
        x_tiled = tf.tile(x_expanded, [1, self.num_classes, 1, 1])  # (batch_size, num_classes, 200, 8)
        
        # Aggiungi una dimensione per espandere all_labels (num_classes -> batch_size, num_classes, num_classes)
        all_labels_tiled = tf.tile(tf.expand_dims(all_labels, 0), [x.shape[0], 1, 1])  # (batch_size, num_classes, num_classes)
        
        # Reshaping per poter passare al modello
        x_reshaped = tf.reshape(x_tiled, [-1, x.shape[1], x.shape[2]])  # (batch_size * num_classes, 200, 8)
        labels_reshaped = tf.reshape(all_labels_tiled, [-1, self.num_classes])  # (batch_size * num_classes, num_classes)

        # Applica il modello per ottenere z e il log-determinante del Jacobiano
        z, log_det_inv = self(x_reshaped, labels_reshaped, training=False)  # (batch_size * num_classes, 200, 8)
        
        # Rimodella z per adattarsi alla dimensione della distribuzione
        z = tf.reshape(z, [-1, 1600])  # (batch_size * num_classes, 1600)
        
        # Calcola la log-likelihood condizionata nello spazio latente
        log_likelihood = self.distribution.log_prob(z) - log_det_inv  # (batch_size * num_classes)
        
        # Rimodella log-likelihood per ottenere (batch_size, num_classes)
        log_likelihoods = tf.reshape(log_likelihood, [x.shape[0], self.num_classes])

        return log_likelihoods




"""
## Predict
"""

# Caricamento dei dati di test
X_test, labels_test, N_ist_test = read_data(path_data_test)

X_test = X_test[:4000]
labels_test = labels_test[:4000]

print(f"Forma di X_test: {X_test.shape}")

# Crea una codifica one-hot delle etichette
labels_test = tf.cast(labels_test, tf.int64)
labels_test_one_hot = tf.one_hot(labels_test, depth=n_class)
print(f"Forma di labels test one hot encoding: {labels_test_one_hot.shape}")


# test_dataset = tf.data.Dataset.from_tensor_slices((X_test, labels_test_one_hot))
# test_dataset = test_dataset.batch(batch_size)

# # Stampa la forma di un singolo batch
# for x_batch, y_batch in test_dataset.take(1):  # Prendi un batch dal dataset per controllare le dimensioni
#     print(f"Forma di un batch di dati: {x_batch.shape}")
#     print(f"Forma di un batch di etichette: {y_batch.shape}")



# Creazione dell'istanza RealNVP
NVP = RealNVP(num_coupling_layers=6, num_classes=n_class)

# NVP.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist_test*(1-validation_split)/batch_size), alpha=ratio_to_stop)))
#Non serve compilare se non devo continuare il training

# Caricamento dei pesi salvati
NVP.load_weights('./models/NVP_cond.weights.h5')



# Ricostruzione dei dati di test
log_likelihood_test = NVP.predict(X_test, labels_test_one_hot)  


log_likelihoods = NVP.predict_for_all_labels(X_test)

print(f"Forma di log_likelihoods: {log_likelihoods.shape}")

# Stampa delle prime 5 righe di log_likelihoods
print("Prime 5 righe di log_likelihoods:")
print(log_likelihoods.numpy()[:5])

# Predizione delle classi usando la log-likelihood massima
predicted_classes = tf.argmax(log_likelihoods, axis=1).numpy()

print(f"Forma di predicted_classes: {predicted_classes.shape}")
# Stampa delle prime 5 righe di predicted_classes
print("Prime 5 righe di predicted_classes:")
print(predicted_classes[:5])




# Caricamento della cronologia dell'addestramento
hist = pd.read_pickle(path_save + 'hist_NVP_cond.pkl')



"""
## Analisi della classificazione
""" 

# Calcola metriche di classificazione
accuracy = accuracy_score(labels_test, predicted_classes)
precision = precision_score(labels_test, predicted_classes, average='weighted')
recall = recall_score(labels_test, predicted_classes, average='weighted')
f1 = f1_score(labels_test, predicted_classes, average='weighted')

# Calcola la matrice di confusione
conf_matrix = confusion_matrix(labels_test, predicted_classes)

# Crea una figura con due sotto-figure
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 14))

# Plot della matrice di confusione
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax1)
ax1.set_title('Confusion Matrix')
ax1.set_xlabel('Predicted Label')
ax1.set_ylabel('True Label')

# Aggiungi le metriche di classificazione come testo nella seconda sotto-figura
metrics_text = (
    f"Accuracy: {accuracy:.4f}\n"
    f"Precision: {precision:.4f}\n"
    f"Recall: {recall:.4f}\n"
    f"F1-Score: {f1:.4f}"
)
ax2.text(0.5, 0.5, metrics_text, fontsize=12, ha='center', va='center')
ax2.set_axis_off()  # Nascondi gli assi

# Salva il grafico
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "Confusion_Matrix_NVP.png"))

# Mostra il grafico
plt.show()