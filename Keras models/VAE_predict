
import os

os.environ["KERAS_BACKEND"] = "tensorflow"

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import keras
from keras import regularizers
from keras import ops
from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_absolute_error
import seaborn as sns
import matplotlib.pyplot as plt
from keras import layers
import scipy.stats as st


# Specify the example you are dealing with
esempio = 'L_FRAME_DT'
# Training and Testing data
ID              = '7_1'
save_ID         = 'Classifier_total_7_1/'
path            = "../" + esempio + '/Dati/'
path_data_train   = path + 'istantrain_' + ID
path_data_test   = path + 'istantest_' + ID
# Saving model
path_save       = "models/"
# Prediction model
restore_ID= 'Classifier_total_7_1/'
path_restore = path + restore_ID
# Which dof monitored
which_channels = [1,2,3,4,5,6,7,8]

n_channels = 8
seq_len = 200
addedd_SNR = 100
# Specify if you are using accelerations =1 or displacements =0
accelerations = 0

def RMS(vect):
    return np.sqrt(np.mean(np.square(vect)))

"""
## Importazione dati
"""

# Read data and create dataset with only desired classes
def read_data(path_data):    
    label_path_class = path_data + '/Damage_class.csv'                                
    labels_class     = np.genfromtxt(label_path_class)
    labels_class     = labels_class.astype('int')
    N_ist = len(labels_class)  

    if accelerations == 1:
        path_rec  = path_data + '/U2_concat_'
    elif accelerations == 0:
        path_rec  = path_data + '/U_concat_'

    if path_data == path_data_train:
        signals_means = np.zeros((n_channels))
        signals_stds = np.zeros((n_channels))
    else:
        signals_means = np.load(path_restore+'/Corrupted_signals_means.npy')
        signals_stds = np.load(path_restore+'/Corrupted_signals_stds.npy')
    # Create the dataset output structure
    X = np.zeros((N_ist, seq_len, n_channels))   #(10000,200,8)
    X_noise = np.zeros((N_ist, seq_len, n_channels))
    for i1 in range(n_channels):
        path_data_var  = path_rec + str(which_channels[i1]) + '.csv'
        X_singledof = pd.read_csv(path_data_var, header=None).to_numpy()[:,0]
        for i2 in range(N_ist):
            # RESHAPE THE SIGNALS
            X[i2,:,i1]= X_singledof[1 + i2*(1+seq_len) : (i2+1)*(1+seq_len)]
            # # CORRUPT THE SIGNALS
            rms_signal = RMS(X[i2,:,i1])
            dev_std    = rms_signal / np.sqrt(addedd_SNR)
            sample = st.norm(0, dev_std)
            X_noise[i2,:,i1] = X[i2,:,i1] + sample.rvs(size=seq_len)
        if path_data == path_data_train:
            # COMPUTE STATISTICS FOR EACH CHANNEL
            # signals_means[i1] = np.mean(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            # signals_stds[i1] = np.std(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            signals_means[i1] = np.mean(np.reshape(X[:,:,i1], (N_ist*seq_len)))
            signals_stds[i1] = np.std(np.reshape(X[:,:,i1], (N_ist*seq_len)))

        # NORMALIZE THE SIGNALS    
        X_noise[:,:,i1] = (X_noise[:,:,i1] - signals_means[i1])/signals_stds[i1]
        # X[:,:,i1] = (X[:,:,i1] - signals_means[i1])/signals_stds[i1]
   
    # if path_data == path_data_train:    
    #     np.save(path_save+'Corrupted_signals_means', signals_means)
    #     np.save(path_save+'Corrupted_signals_stds', signals_stds)
       
    # return X_noise, labels_class, N_ist
    return X_noise, labels_class, N_ist


"""
## Sampling
"""

class Sampling(layers.Layer):
    """Uses (z_mean, z_log_var) to sample z, the vector encoding a digit."""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.seed_generator = keras.random.SeedGenerator(1337)

    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = ops.shape(z_mean)[0]
        dim = ops.shape(z_mean)[1]
        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)
        return z_mean + ops.exp(0.5 * z_log_var) * epsilon
    
    


n_class = 8
latent_dim = 4

# Hyperparameters
validation_split = 0.20
batch_size = 32
n_epochs = 150  #250
early_stop_epochs=15
initial_lr = 1e-3
decay_length = 0.8
ratio_to_stop = 0.05

filter_1      = 32;   filter_2      = 64;   filter_3      = 32
kernel_size_1 = 25;   kernel_size_2 =  13;   kernel_size_3 = 7
neurons_4 = 64
neurons_5 = 16
attivaz_conv = 'tanh'
attivaz_mlp = 'tanh'
k_reg = 1e-3
b_reg = 1e-3
rate_drop = 0.05


"""
## Build the encoder 
"""

encoder_inputs  = layers.Input(shape=(seq_len, n_channels), name='Convolutional_inputs')
x = layers.Conv1D(filters=filter_1, kernel_size=kernel_size_1, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_1')(encoder_inputs)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)   #Gli strati Dropout vengono utilizzati per regolarizzare il modello durante l'addestramento, disattivando casualmente una frazione di neuroni. Questo aiuta a prevenire l'overfitting.
x = layers.Conv1D(filters=filter_2, kernel_size=kernel_size_2, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_2')(x)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)
x = layers.Conv1D(filters=filter_3, kernel_size=kernel_size_3, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_3')(x)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)
x = layers.Flatten()(x)
x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(x)
x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)

z_mean = layers.Dense(latent_dim, activation=None, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='z_mean')(x)
z_log_var = layers.Dense(latent_dim, activation=None, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='z_log_var')(x)
z = Sampling()([z_mean, z_log_var])

# Definisci il modello
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
encoder.summary()

"""
## Build the decoder 
"""

latent_inputs_decoder = layers.Input(shape=(latent_dim,), name='Latent_inputs')

x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1_decoder')(latent_inputs_decoder)
x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2_decoder')(x)
x = layers.Dense(units=filter_3 * (seq_len // 8), activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3_decoder')(x)
x = layers.Reshape((seq_len // 8, filter_3))(x)

# Applica strati Conv1DTranspose (o Conv1D per upsampling)
x = layers.Conv1DTranspose(filters=filter_3, kernel_size=kernel_size_3, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_1')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1DTranspose(filters=filter_2, kernel_size=kernel_size_2, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_2')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1DTranspose(filters=filter_1, kernel_size=kernel_size_1, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_3')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

# Ultimo livello per tornare alla forma originale
decoder_outputs = layers.Conv1D(filters=n_channels, kernel_size=kernel_size_1, activation=None, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Conv_1_decoder')(x)

# Definisci il modello
decoder = keras.Model(latent_inputs_decoder, decoder_outputs, name='decoder')
decoder.summary()


"""
## Build the Dense layer
"""

latent_inputs_classifier = layers.Input(shape=(latent_dim,), name='Latent_inputs')

x = layers.Dense(units=64, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(latent_inputs_classifier)
x = layers.Dense(units=32, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)
Dense_output = layers.Dense(n_class,activation=keras.activations.softmax,kernel_regularizer=regularizers.l2(k_reg),bias_regularizer=regularizers.l2(b_reg),name='Dense_3_with_Softmax')(x)

# Definisci il modello
classifier = keras.Model(latent_inputs_classifier, Dense_output, name='decoder')
classifier.summary()





"""
## Define the VAE class
"""

class VAE(keras.Model):
    def __init__(self, encoder, decoder, classifier,**kwargs):
        super().__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.classifier = classifier
        self.total_loss_tracker = keras.metrics.Mean(name="total_loss")
        self.reconstruction_loss_tracker = keras.metrics.Mean(name="reconstruction_loss")
        self.kl_loss_tracker = keras.metrics.Mean(name="kl_loss")
        self.classification_loss_tracker = keras.metrics.Mean(name="classification_loss")

    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
        ]

    def train_step(self, data):

        observations, damage_class_labels = data


        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(observations)

            reconstruction = self.decoder(z)

            # Predizione per la classificazione
            classification_preds = self.classifier(z)

            reconstruction_loss = ops.mean(
                ops.sum(
                    # keras.losses.binary_crossentropy(observations, reconstruction), #La funzione keras.losses.binary_crossentropy(data, reconstruction) restituisce un tensore bidimensionale di forma (batch_size, time_steps). 
                                                                                      #Questo avviene perché binary_crossentropy calcola la perdita per ogni time step, non per ogni canale.
                    keras.losses.mean_squared_error(observations, reconstruction),  # Calcola la perdita MSE tra dati originali e ricostruiti
                    axis=1,   
                )
            )
            
            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))
            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))

            # Perdita di classificazione (categorical crossentropy)
            classification_loss = keras.losses.sparse_categorical_crossentropy(damage_class_labels, classification_preds)
            classification_loss = tf.reduce_mean(classification_loss)

            beta = 1.0
            gamma = 60.0
            total_loss = reconstruction_loss + beta * kl_loss + gamma * classification_loss

        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))

        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        self.classification_loss_tracker.update_state(classification_loss)
        return {
            "loss": self.total_loss_tracker.result(),
            "reconstruction_loss": self.reconstruction_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
            "classification_loss": self.classification_loss_tracker.result(),
        }
    
    
    def test_step(self, data):
        observations, damage_class_labels = data
        z_mean, z_log_var, z = self.encoder(observations)
        reconstruction = self.decoder(z)
        classification_preds = self.classifier(z)

        # Calcolo della perdita per il test
        reconstruction_loss = ops.mean(
            ops.sum(
                # keras.losses.binary_crossentropy(data, reconstruction), #La funzione keras.losses.binary_crossentropy(data, reconstruction) restituisce un tensore bidimensionale di forma (batch_size, time_steps). 
                                                                          #Questo avviene perché binary_crossentropy calcola la perdita per ogni time step, non per ogni canale.
                keras.losses.mean_squared_error(observations, reconstruction),  # Calcola la perdita MSE tra dati originali e ricostruiti
                axis=1,   
                )
            )
        
        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)
        kl_loss = tf.reduce_mean(kl_loss)

        classification_loss = keras.losses.sparse_categorical_crossentropy(damage_class_labels, classification_preds)
        classification_loss = tf.reduce_mean(classification_loss)

        beta = 1.0
        gamma = 60.0
        total_loss = reconstruction_loss + beta * kl_loss + gamma * classification_loss

        return {
            "loss": total_loss,
            "reconstruction_loss": reconstruction_loss,
            "kl_loss": kl_loss,
            "classification_loss": classification_loss,
        }
    
    def call(self, inputs):
        # Passaggio attraverso l'encoder
        z_mean, z_log_var, z = self.encoder(inputs)
        
        # Decodifica del campione z
        reconstructed = self.decoder(z)

        # Decodifica del campione z
        classified = self.classifier(z)
        
        return reconstructed, classified






"""
## Predict
"""

# Caricamento dei dati di test
X_test, labels_test, N_ist_test = read_data(path_data_test)

print(f"Forma di X_test: {X_test.shape}")

# Creare dataset TensorFlow per il testing
test_dataset = tf.data.Dataset.from_tensor_slices((X_test, labels_test))
test_dataset = test_dataset.batch(batch_size)


# Creazione dell'istanza VAE
vae = VAE(encoder, decoder, classifier)
vae.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist_test*(1-validation_split)/batch_size), alpha=ratio_to_stop)))

# Caricamento dei pesi salvati
vae.load_weights('./models/VAE_1D.weights.h5')


# Ricostruzione dei dati di test
X_test_reconstructed, X_test_classified = vae.predict(test_dataset)

# Calcolo della perdita di ricostruzione (MSE tra dati originali e ricostruiti)
reconstruction_loss = ops.mean(ops.sum(keras.losses.mean_squared_error(X_test, X_test_reconstructed), axis=1))

# Caricamento della cronologia dell'addestramento
hist = pd.read_pickle(path_save + 'hist_VAE_1D.pkl')




output_dir = "output_VAE_1D"

"""
## Analisi della ricostruzione
"""

# MSE e MAE tra i dati ricostruiti e originali
mse_reconstruction = mean_squared_error(X_test.flatten(), X_test_reconstructed.flatten())
mae_reconstruction = mean_absolute_error(X_test.flatten(), X_test_reconstructed.flatten())

print(f"Mean Squared Error (MSE) sulla ricostruzione: {mse_reconstruction}")
print(f"Mean Absolute Error (MAE) sulla ricostruzione: {mae_reconstruction}")

# def compute_ssim_for_time_series(X_test, X_test_reconstructed, max_val=1.0):
#     # Lista per memorizzare i valori di SSIM per ogni canale
#     ssim_values = []

#     # Itera attraverso il batch
#     for i in range(len(X_test)):
#         # Calcola il SSIM per ogni canale/sensore (dim 1) tra la serie temporale originale e quella ricostruita
#         for channel in range(X_test.shape[-1]):
#             # Estrae la serie temporale per il canale corrente
#             ssim_value = tf.image.ssim(
#                 tf.expand_dims(X_test[i, :, channel], axis=-1), 
#                 tf.expand_dims(X_test_reconstructed[i, :, channel], axis=-1), 
#                 max_val=max_val
#             ).numpy()
#             ssim_values.append(ssim_value)
    
#     # Calcola la media di SSIM per tutto il dataset
#     mean_ssim = np.mean(ssim_values)
#     return mean_ssim

# # Esegui il calcolo del SSIM
# mean_ssim = compute_ssim_for_time_series(X_test, X_test_reconstructed, max_val=1.0)
# print(f"Structural Similarity Index (SSIM) for time series: {mean_ssim}")


# Seleziona un esempio casuale
idx = np.random.randint(0, X_test.shape[0])
original_signal = X_test[idx]
reconstructed_signal = X_test_reconstructed[idx]

# Plot dei segnali
plt.plot(original_signal.flatten(), label='Originale')
plt.plot(reconstructed_signal.flatten(), label='Ricostruito')
plt.legend()
plt.title(f"Segnale Originale vs Ricostruito - Esempio {idx}")
plt.show()


"""
## Analisi della classificazione
"""

# Ottieni le classi previste
predicted_classes = np.argmax(X_test_classified, axis=1)

# Calcola metriche di classificazione
accuracy = accuracy_score(labels_test, predicted_classes)
precision = precision_score(labels_test, predicted_classes, average='weighted')
recall = recall_score(labels_test, predicted_classes, average='weighted')
f1 = f1_score(labels_test, predicted_classes, average='weighted')

# Calcola la matrice di confusione
conf_matrix = confusion_matrix(labels_test, predicted_classes)

# Crea una figura con due sotto-figure
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 14))

# Plot della matrice di confusione
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax1)
ax1.set_title('Confusion Matrix')
ax1.set_xlabel('Predicted Label')
ax1.set_ylabel('True Label')

# Aggiungi le metriche di classificazione come testo nella seconda sotto-figura
metrics_text = (
    f"Accuracy: {accuracy:.4f}\n"
    f"Precision: {precision:.4f}\n"
    f"Recall: {recall:.4f}\n"
    f"F1-Score: {f1:.4f}"
)
ax2.text(0.5, 0.5, metrics_text, fontsize=12, ha='center', va='center')
ax2.set_axis_off()  # Nascondi gli assi

# Salva il grafico
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "Confusion_Matrix_VAE.png"))

# Mostra il grafico
plt.show()


