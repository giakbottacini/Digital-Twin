"""
Title: Variational AutoEncoder
Author: [fchollet](https://twitter.com/fchollet)
Date created: 2020/05/03
Last modified: 2024/04/24
Description: Convolutional Variational AutoEncoder (VAE) trained on MNIST digits.
Accelerator: GPU
"""

"""
## Setup
"""

import os

os.environ["KERAS_BACKEND"] = "tensorflow"

import numpy as np
import tensorflow as tf
import keras
from keras import ops
from keras import layers
from keras import regularizers
from keras import losses
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as st

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_absolute_error
import seaborn as sns
from sklearn.manifold import MDS, TSNE
from sklearn.decomposition import PCA

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score


#VAE for DT per classificare il livello di danno

which_class = 1   # Prendiamo solo i casi in cui il danno è nella regione which_class

# Specify the example you are dealing with
esempio = 'L_FRAME_DT'
# Training and Testing data
ID              = '7_1'
save_ID         = 'Level_Regressor_7_' + str(which_class) + '/'
path            = '../' + esempio + '/Dati/'
path_data_train   = path + 'istantrain_' + ID
path_data_test   = path + 'istantest_' + ID
# Saving model
path_save       = "models/"
# Prediction model
restore_ID= 'Level_Regressor_7_' + str(which_class) + '/'
path_restore = path + restore_ID


# Which dof monitored
which_channels = [1,2,3,4,5,6,7,8]

n_channels = 8
seq_len = 200
# addedd_SNR = 100
# Specify if you are using accelerations =1 or displacements =0
accelerations = 0



# Questa funzione calcola il valore quadratico medio (RMS) di un vettore di segnale, utile per misurare l'energia del segnale e per 
# aggiungere rumore durante la corruzione dei segnali.
def RMS(vect):
    return np.sqrt(np.mean(np.square(vect)))


# ----------------------------------------------------------------------------

"""
## Importazione dati
"""

num_classi = 5   # Definisci il numero di classi

def read_data(path_data, addedd_SNR):    
    label_path_class = path_data + '/Damage_class.csv'                                
    labels_class     = np.genfromtxt(label_path_class)
    labels_class     = labels_class.astype('int')
    label_path_level = path_data + '/Damage_level.csv'                                
    labels_level     = np.genfromtxt(label_path_level)
    N_ist = len(labels_level)  
    if accelerations == 1:
        path_rec  = path_data + '/U2_concat_'
    elif accelerations == 0:
        path_rec  = path_data + '/U_concat_'
    if path_data == path_data_train:
        signals_means = np.zeros((n_channels))
        signals_stds = np.zeros((n_channels))
    else:
        signals_means = np.load(path_restore+'/Corrupted_signals_means.npy')
        signals_stds = np.load(path_restore+'/Corrupted_signals_stds.npy')
    # Create the dataset output structure
    X       = np.zeros((N_ist, seq_len, n_channels))
    for i1 in range(n_channels):
        path_data_var  = path_rec + str(which_channels[i1]) + '.csv'
        X_singledof = pd.read_csv(path_data_var, header=None).to_numpy()[:,0]
        for i2 in range(N_ist):
            # RESHAPE THE SIGNALS
            X[i2,:,i1]= X_singledof[1 + i2*(1+seq_len) : (i2+1)*(1+seq_len)]  

    # remove all the data relative except the which_class case
    i1 = 0
    i2 = 0
    while i1<N_ist:
        if not labels_class[i1] == which_class:
            labels_level = np.delete(labels_level, i1-i2, 0)
            X = np.delete(X, i1-i2, 0)
            i2+=1
        i1+=1
   
   
    N_ist = len(labels_level)
    X_noise = np.zeros((N_ist, seq_len, n_channels))
    for i1 in range(n_channels):
        for i2 in range(N_ist):
            # CORRUPT THE SIGNALS
            rms_signal = RMS(X[i2,:,i1])
            dev_std    = rms_signal / np.sqrt(addedd_SNR)
            sample = st.norm(0, dev_std)
            X_noise[i2,:,i1] = X[i2,:,i1] + sample.rvs(size=seq_len)
   
    if path_data == path_data_train:
        # COMPUTE STATISTICS FOR EACH CHANNEL
        for i1 in range(n_channels):
            signals_means[i1] = np.mean(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            signals_stds[i1] = np.std(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
        # np.save(path_save+'Corrupted_signals_means', signals_means)
        # np.save(path_save+'Corrupted_signals_stds', signals_stds)
        level_mean = np.mean(labels_level)
        level_std  = np.std(labels_level)
        # np.save(path_save+'Damage_level_mean', level_mean)
        # np.save(path_save+'Damage_level_std', level_std)
        labels_level = (labels_level - level_mean)/level_std
   
    # NORMALIZE THE SIGNALS    
    for i1 in range(n_channels):
        X_noise[:,:,i1] = (X_noise[:,:,i1] - signals_means[i1])/signals_stds[i1]

    
    # Trova il valore minimo e massimo in labels_train
    min_val = np.min(labels_level)
    max_val = np.max(labels_level)

    # Suddividi labels_train in 5 classi (range uniformi) (ho visto che in questo modo le classi sono uniformi)
    bins = np.linspace(min_val, max_val, num_classi + 1)

    # Usa np.digitize per assegnare a ciascun valore la sua classe
    labels_classi = np.digitize(labels_level, bins, right=True)

    # Assicuriamoci che i valori siano compresi tra 1 e 5
    labels_classi = np.clip(labels_classi, 1, num_classi)

    # Sottrai 1 per convertire le classi da 1-5 a 0-4
    labels_classi -= 1
       
    return X_noise, labels_classi, N_ist



"""
## Create a sampling layer
"""

class Sampling(layers.Layer):
    """Uses (z_mean, z_log_var) to sample z, the vector encoding a digit."""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.seed_generator = keras.random.SeedGenerator(1337)

    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = ops.shape(z_mean)[0]
        dim = ops.shape(z_mean)[1]
        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)
        return z_mean + ops.exp(0.5 * z_log_var) * epsilon



"""
## Using Matteo's architecture
"""

# ----------------------------------------------------------------------------
n_class = 8
latent_dim = 3

# Hyperparameters
validation_split = 0.20
batch_size = 32
n_epochs = 250
early_stop_epochs = 25   #40 per classe 7
initial_lr = 1e-3
decay_length = 0.8
ratio_to_stop = 0.05

filter_1      = 32 ;   filter_2      = 64;   filter_3      = 32
kernel_size_1 = 25;   kernel_size_2 =  13;   kernel_size_3 = 7
neurons_4 = 64
neurons_5 = 16
attivaz_conv = 'tanh'
attivaz_mlp = 'tanh'
k_reg = 1e-3   #Puoi aumentare il peso della regolarizzazione L2 per penalizzare i pesi grandi, il che potrebbe aiutare il modello a imparare una 
b_reg = 1e-3   #rappresentazione più semplice dei dati.
rate_drop = 0.1  #Percentuale di neuroni disattivati 

"""
## Build the encoder 
"""

encoder_inputs  = layers.Input(shape=(seq_len, n_channels), name='Convolutional_inputs')
x = layers.Conv1D(filters=filter_1, kernel_size=kernel_size_1, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_1')(encoder_inputs)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)   #Gli strati Dropout vengono utilizzati per regolarizzare il modello durante l'addestramento, disattivando casualmente una frazione di neuroni. Questo aiuta a prevenire l'overfitting.

x = layers.Conv1D(filters=filter_2, kernel_size=kernel_size_2, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_2')(x)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1D(filters=filter_3, kernel_size=kernel_size_3, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_3')(x)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Flatten()(x)

x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(x)
x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)

z_mean = layers.Dense(latent_dim, activation=None, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='z_mean')(x)
z_log_var = layers.Dense(latent_dim, activation=None, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='z_log_var')(x)
z = Sampling()([z_mean, z_log_var])

# Definisci il modello
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
encoder.summary()

"""
## Build the decoder 
"""

latent_inputs_decoder = layers.Input(shape=(latent_dim,), name='Latent_inputs')

x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1_decoder')(latent_inputs_decoder)
x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2_decoder')(x)
x = layers.Dense(units=filter_3 * (seq_len // 8), activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3_decoder')(x)
x = layers.Reshape((seq_len // 8, filter_3))(x)

# Applica strati Conv1DTranspose (o Conv1D per upsampling)
x = layers.Conv1DTranspose(filters=filter_3, kernel_size=kernel_size_3, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_1')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1DTranspose(filters=filter_2, kernel_size=kernel_size_2, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_2')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1DTranspose(filters=filter_1, kernel_size=kernel_size_1, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_3')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

# Ultimo livello per tornare alla forma originale
decoder_outputs = layers.Conv1D(filters=n_channels, kernel_size=kernel_size_1, activation=None, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Conv_1_decoder')(x)

# Definisci il modello
decoder = keras.Model(latent_inputs_decoder, decoder_outputs, name='decoder')
decoder.summary()




"""
## Build the Dense layer
"""

latent_inputs_classifier = layers.Input(shape=(latent_dim,), name='Latent_inputs')

x = layers.Dense(units=64, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(latent_inputs_classifier)
x = layers.Dense(units=32, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)
Dense_output = layers.Dense(num_classi,activation=keras.activations.softmax,kernel_regularizer=regularizers.l2(k_reg),bias_regularizer=regularizers.l2(b_reg),name='Dense_3_with_Softmax')(x)

# Definisci il modello
classifier = keras.Model(latent_inputs_classifier, Dense_output, name='classifier')
classifier.summary()





"""
## Define the VAE class
"""

class VAE(keras.Model):
    def __init__(self, encoder, decoder, classifier,**kwargs):
        super().__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.classifier = classifier
        self.total_loss_tracker = keras.metrics.Mean(name="total_loss")
        self.reconstruction_loss_tracker = keras.metrics.Mean(name="reconstruction_loss")
        self.kl_loss_tracker = keras.metrics.Mean(name="kl_loss")
        self.classification_loss_tracker = keras.metrics.Mean(name="classification_loss")

    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
        ]

    def train_step(self, data):

        observations, damage_level_labels = data


        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(observations)

            reconstruction = self.decoder(z)

            # Predizione per la classificazione
            classification_preds = self.classifier(z)

            reconstruction_loss = ops.mean(
                ops.sum(
                    # keras.losses.binary_crossentropy(observations, reconstruction), #La funzione keras.losses.binary_crossentropy(data, reconstruction) restituisce un tensore bidimensionale di forma (batch_size, time_steps). 
                                                                                      #Questo avviene perché binary_crossentropy calcola la perdita per ogni time step, non per ogni canale.
                    keras.losses.mean_squared_error(observations, reconstruction),  # Calcola la perdita MSE tra dati originali e ricostruiti
                    axis=1,   
                )
            )
            
            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))
            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))

            # Perdita di classificazione (categorical crossentropy)
            classification_loss = keras.losses.sparse_categorical_crossentropy(damage_level_labels, classification_preds)
            classification_loss = tf.reduce_mean(classification_loss)

            beta = 1.0
            gamma = 60.0   #100 per la classe 7
            total_loss = reconstruction_loss + beta * kl_loss + gamma * classification_loss

        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))

        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        self.classification_loss_tracker.update_state(classification_loss)
        return {
            "loss": self.total_loss_tracker.result(),
            "reconstruction_loss": self.reconstruction_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
            "classification_loss": self.classification_loss_tracker.result(),
        }
    
    
    def test_step(self, data):
        observations, damage_level_labels = data
        z_mean, z_log_var, z = self.encoder(observations)
        reconstruction = self.decoder(z)
        classification_preds = self.classifier(z)

        # Calcolo della perdita per il test
        reconstruction_loss = ops.mean(
            ops.sum(
                # keras.losses.binary_crossentropy(data, reconstruction), #La funzione keras.losses.binary_crossentropy(data, reconstruction) restituisce un tensore bidimensionale di forma (batch_size, time_steps). 
                                                                          #Questo avviene perché binary_crossentropy calcola la perdita per ogni time step, non per ogni canale.
                keras.losses.mean_squared_error(observations, reconstruction),  # Calcola la perdita MSE tra dati originali e ricostruiti
                axis=1,   
                )
            )
        
        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)
        kl_loss = tf.reduce_mean(kl_loss)

        classification_loss = keras.losses.sparse_categorical_crossentropy(damage_level_labels, classification_preds)
        classification_loss = tf.reduce_mean(classification_loss)

        beta = 1.0
        gamma = 60.0   #100 per la classe 7
        total_loss = reconstruction_loss + beta * kl_loss + gamma * classification_loss

        return {
            "loss": total_loss,
            "reconstruction_loss": reconstruction_loss,
            "kl_loss": kl_loss,
            "classification_loss": classification_loss,
        }
    
    
    def call(self, inputs):
        # Passaggio attraverso l'encoder
        z_mean, z_log_var, z = self.encoder(inputs)
        
        # Decodifica del campione z
        reconstructed = self.decoder(z)

        # Decodifica del campione z
        classified = self.classifier(z)
        
        return reconstructed, classified



"""
## Funzioni utili
"""


def plot_label_clusters(vae, data, labels):
    # display a 2D plot of the digit classes in the latent space
    z_mean, _, _ = vae.encoder.predict(data, verbose=0)

    print(f"Forma di z_mean: {z_mean.shape}")
    print(f"Primi elementi di z_mean:\n{z_mean[0:4,:]}")

    plt.figure(figsize=(12, 10))
    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)
    plt.colorbar()
    plt.xlabel("z_mean[0]")
    plt.ylabel("z_mean[1]")
    # Imposta il titolo della figura
    plt.suptitle(f'Grouped by damage class', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_2d.png"))
    plt.close()




def plot_label_clusters_3d(vae, data, labels):
    # display a 3D plot of the digit classes in the latent space
    z_mean, _, _ = vae.encoder.predict(data, verbose=0)

    print(f"Forma di z_mean: {z_mean.shape}")
    print(f"Primi elementi di z_mean:\n{z_mean[0:4,:]}")

    if z_mean.shape[1] < 3:
        print("Attenzione: z_mean ha meno di 3 dimensioni. Potrebbe non essere possibile creare un grafico 3D.")
        return
    

    # Plot using nothing
    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')
    scatter = ax.scatter(z_mean[:, 0], z_mean[:, 1], z_mean[:, 2], c=labels, cmap='viridis')
    color_bar = fig.colorbar(scatter, ax=ax)
    color_bar.set_label('Classi')
    ax.set_xlabel("z_mean[0]")
    ax.set_ylabel("z_mean[1]")
    ax.set_zlabel("z_mean[2]")
    plt.suptitle(f'Grouped by damage class in 3D latent space', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_3d.png"))
    plt.show()




    # # Plot using MDS
    # mds = MDS(n_components=3)
    # z_mds = mds.fit_transform(z_mean)

    # fig = plt.figure(figsize=(12, 10))
    # ax = fig.add_subplot(111, projection='3d')
    # scatter = ax.scatter(z_mds[:, 0], z_mds[:, 1], z_mds[:, 2], c=labels, cmap='viridis')
    # color_bar = fig.colorbar(scatter, ax=ax)
    # color_bar.set_label('Classi')
    # ax.set_xlabel("MDS[0]")
    # ax.set_ylabel("MDS[1]")
    # ax.set_zlabel("MDS[2]")
    # plt.suptitle(f'Grouped by damage class in 3D latent space using MDS', fontsize=16)
    # plt.savefig(os.path.join(output_dir, "label_clusters_mds_3d.png"))
    # plt.show()

    # # Plot using TSNE  (in teoria serve più che altro se hai input categoriale)
    # tsne = TSNE(n_components=3)
    # z_tsne = tsne.fit_transform(z_mean)

    # fig = plt.figure(figsize=(12, 10))
    # ax = fig.add_subplot(111, projection='3d')
    # scatter = ax.scatter(z_tsne[:, 0], z_tsne[:, 1], z_tsne[:, 2], c=labels, cmap='viridis')
    # color_bar = fig.colorbar(scatter, ax=ax)
    # color_bar.set_label('Classi')
    # ax.set_xlabel("TSNE[0]")
    # ax.set_ylabel("TSNE[1]")
    # ax.set_zlabel("TSNE[2]")
    # plt.suptitle(f'Grouped by damage class in 3D latent space using TSNE', fontsize=16)
    # plt.savefig(os.path.join(output_dir, "label_clusters_tsne_3d.png"))
    # plt.show()

    # Plot using PCA
    # pca = PCA(n_components=3)
    # z_pca = pca.fit_transform(z_mean)

    # fig = plt.figure(figsize=(12, 10))
    # ax = fig.add_subplot(111, projection='3d')
    # scatter = ax.scatter(z_pca[:, 0], z_pca[:, 1], z_pca[:, 2], c=labels, cmap='viridis')
    # color_bar = fig.colorbar(scatter, ax=ax)
    # color_bar.set_label('Classi')
    # ax.set_xlabel("PCA[0]")
    # ax.set_ylabel("PCA[1]")
    # ax.set_zlabel("PCA[2]")
    # plt.suptitle(f'Grouped by damage class in 3D latent space using PCA', fontsize=16)
    # plt.savefig(os.path.join(output_dir, "label_clusters_pca_3d.png"))
    # plt.show()


# Crea la cartella se non esiste
output_dir = "output_VAE_danno"
if not os.path.exists(output_dir):
    os.makedirs(output_dir)




train_or_predict = 0   # 1: training, 0: predict                                       


if train_or_predict:

    """
    ## Model training
    """

    X_train, labels_train, N_ist_train = read_data(path_data_train, 100)

    print(f"Forma di X_train: {X_train.shape}")
    print(f"Forma di labels_train: {labels_train.shape}")


    # Separare i dati in training e validation set
    train_observations, val_observations, train_labels, val_labels = train_test_split(X_train, labels_train, test_size=validation_split, random_state=42)

    # Creare dataset TensorFlow per il training
    train_dataset = tf.data.Dataset.from_tensor_slices((train_observations, train_labels))
    train_dataset = train_dataset.batch(batch_size)

    # Creare dataset TensorFlow per la validazione
    val_dataset = tf.data.Dataset.from_tensor_slices((val_observations, val_labels))
    val_dataset = val_dataset.batch(batch_size)

    vae = VAE(encoder, decoder, classifier)

    vae.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist_train*(1-validation_split)/batch_size), alpha=ratio_to_stop)))

    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stop_epochs, restore_best_weights=True)


    # Allenamento del modello
    history = vae.fit(train_dataset, epochs=n_epochs, validation_data=val_dataset, batch_size=batch_size, verbose=2, callbacks=[early_stop])



    # Salva lo storico dell'addestramento in formato pickle
    hist = pd.DataFrame(history.history)  # Converti history.history (dati storici dell'addestramento) in un DataFrame di pandas
    hist['epoch'] = history.epoch  # Aggiungi una colonna per le epoche. history.epoch è una lista che contiene i numeri delle epoche per cui sono stati registrati i dati.

    # Salva il DataFrame
    try:
        hist.to_pickle(os.path.join(path_save, 'hist_VAE_danno.pkl'))   #Salva il DataFrame hist in un file con formato pickle.
        print(f"Storico salvato in {os.path.join(path_save, 'hist_VAE_danno.pkl')}")
    except Exception as e:
        print(f"Errore durante il salvataggio dello storico: {e}")

    # Salva il modello
    try:
        vae.save(os.path.join(path_save, 'model_VAE_danno.keras'))   # Salva il modello vae addestrato in formato Keras
        print(f"Modello salvato in {os.path.join(path_save, 'model_VAE_danno.keras')}")
    except Exception as e:
        print(f"Errore durante il salvataggio del modello: {e}")


    # Crea il nome del file con il valore di which_class e il percorso di salvataggio
    filename = os.path.join(path_save, f'VAE_danno_{which_class}.weights.h5')

    # Salva i pesi
    vae.save_weights(filename)

    print(f"Pesi salvati in {filename}")


    """
    ## Output
    """

    # Assicurati che la directory esista
    os.makedirs(output_dir, exist_ok=True)

    # Nome del file in base al valore di which_class
    file_name = f"losses_{which_class}.png"
    file_path = os.path.join(output_dir, file_name)

    # Plot combinato per la training loss e la validation loss
    plt.figure(figsize=(15, 5))  # Dimensioni del plot
    plt.plot(history.history["loss"], label="Training Loss", color='blue')
    plt.plot(history.history["val_loss"], label="Validation Loss", color='orange')
    plt.title("Training and Validation Loss")
    plt.ylabel("Loss")
    plt.xlabel("Epoch")
    plt.legend(loc="upper right")
    plt.grid(True)

    # Salva il plot con il nome file specifico
    plt.savefig(file_path)
    plt.show()
    plt.close()


    # plot_label_clusters(vae, X_train , labels_train)
    plot_label_clusters_3d(vae, X_train , labels_train)


else:

    """
    ## Predict
    """

    # Caricamento dei dati di test
    X_test, labels_test, N_ist_test = read_data(path_data_test, 100)

    print(f"Forma di X_test: {X_test.shape}")

    # Creare dataset TensorFlow per il testing
    # test_dataset = tf.data.Dataset.from_tensor_slices((X_test, labels_test))
    # test_dataset = test_dataset.batch(batch_size)


    # Creazione dell'istanza VAE
    vae = VAE(encoder, decoder, classifier)
    #vae.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist_test*(1-validation_split)/batch_size), alpha=ratio_to_stop)))


    # Crea il nome del file con il valore di which_class e il percorso di salvataggio
    filename = os.path.join(path_save, f'VAE_danno_{which_class}.weights.h5')
    # Caricamento dei pesi salvati
    vae.load_weights(filename)


    # Ricostruzione dei dati di test
    X_test_reconstructed, X_test_classified = vae.predict(X_test)

    # Calcolo della perdita di ricostruzione (MSE tra dati originali e ricostruiti)
    reconstruction_loss = ops.mean(ops.sum(keras.losses.mean_squared_error(X_test, X_test_reconstructed), axis=1))

    # Caricamento della cronologia dell'addestramento
    hist = pd.read_pickle(path_save + 'hist_VAE_danno.pkl')

    # Ottieni le classi previste
    predicted_classes = np.argmax(X_test_classified, axis=1)



    """
    ## Analisi della classificazione
    """

    # Calcola metriche di classificazione
    accuracy = accuracy_score(labels_test, predicted_classes)
    precision = precision_score(labels_test, predicted_classes, average='weighted')
    recall = recall_score(labels_test, predicted_classes, average='weighted')
    f1 = f1_score(labels_test, predicted_classes, average='weighted')

    # Calcola la matrice di confusione
    conf_matrix = confusion_matrix(labels_test, predicted_classes)

    # Crea una figura con due sotto-figure
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 14))

    # Plot della matrice di confusione
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax1)
    ax1.set_title('Confusion Matrix')
    ax1.set_xlabel('Predicted Label')
    ax1.set_ylabel('True Label')

    # Aggiungi le metriche di classificazione come testo nella seconda sotto-figura
    metrics_text = (
        f"Accuracy: {accuracy:.4f}\n"
        f"Precision: {precision:.4f}\n"
        f"Recall: {recall:.4f}\n"
        f"F1-Score: {f1:.4f}"
    )
    ax2.text(0.5, 0.5, metrics_text, fontsize=12, ha='center', va='center')
    ax2.set_axis_off()  # Nascondi gli assi

    # Salva il grafico
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "Confusion_Matrix_VAE.png"))

    # Mostra il grafico
    plt.show()