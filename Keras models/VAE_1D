"""
Title: Variational AutoEncoder
Author: [fchollet](https://twitter.com/fchollet)
Date created: 2020/05/03
Last modified: 2024/04/24
Description: Convolutional Variational AutoEncoder (VAE) trained on MNIST digits.
Accelerator: GPU
"""

"""
## Setup
"""

import os

os.environ["KERAS_BACKEND"] = "tensorflow"

import numpy as np
import tensorflow as tf
import keras
from keras import ops
from keras import layers
from keras import regularizers
from keras import losses
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as st

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_absolute_error
import seaborn as sns
from sklearn.manifold import MDS, TSNE
from sklearn.decomposition import PCA

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score


#VAE for DT

# Specify the example you are dealing with
esempio = 'L_FRAME_DT'
# Training and Testing data
ID              = '7_1'
save_ID         = 'Classifier_total_7_1/'
path            = "../" + esempio + '/Dati/'
path_data_train   = path + 'istantrain_' + ID
path_data_test   = path + 'istantest_' + ID
# Saving model
path_save       = "models/"
# Prediction model
restore_ID= 'Classifier_total_7_1/'
path_restore = path + restore_ID

# Which dof monitored
which_channels = [1,2,3,4,5,6,7,8]

n_channels = 8
seq_len = 200
# addedd_SNR = 100
# Specify if you are using accelerations =1 or displacements =0
accelerations = 0

# Questa funzione calcola il valore quadratico medio (RMS) di un vettore di segnale, utile per misurare l'energia del segnale e per 
# aggiungere rumore durante la corruzione dei segnali.
def RMS(vect):
    return np.sqrt(np.mean(np.square(vect)))


# ----------------------------------------------------------------------------

"""
## Importazione dati
"""

# Read data and create dataset with only desired classes
def read_data(path_data, addedd_SNR):    
    label_path_class = path_data + '/Damage_class.csv'                                
    labels_class     = np.genfromtxt(label_path_class)
    labels_class     = labels_class.astype('int')
    N_ist = len(labels_class)  

    if accelerations == 1:
        path_rec  = path_data + '/U2_concat_'
    elif accelerations == 0:
        path_rec  = path_data + '/U_concat_'

    if path_data == path_data_train:
        signals_means = np.zeros((n_channels))
        signals_stds = np.zeros((n_channels))
    else:
        signals_means = np.load(path_restore+'/Corrupted_signals_means.npy')
        signals_stds = np.load(path_restore+'/Corrupted_signals_stds.npy')
    # Create the dataset output structure
    X = np.zeros((N_ist, seq_len, n_channels))   #(10000,200,8)
    X_noise = np.zeros((N_ist, seq_len, n_channels))
    for i1 in range(n_channels):
        path_data_var  = path_rec + str(which_channels[i1]) + '.csv'
        X_singledof = pd.read_csv(path_data_var, header=None).to_numpy()[:,0]
        for i2 in range(N_ist):
            # RESHAPE THE SIGNALS
            X[i2,:,i1]= X_singledof[1 + i2*(1+seq_len) : (i2+1)*(1+seq_len)]
            # # CORRUPT THE SIGNALS
            rms_signal = RMS(X[i2,:,i1])
            dev_std    = rms_signal / np.sqrt(addedd_SNR)
            sample = st.norm(0, dev_std)
            X_noise[i2,:,i1] = X[i2,:,i1] + sample.rvs(size=seq_len)
        if path_data == path_data_train:
            # COMPUTE STATISTICS FOR EACH CHANNEL
            signals_means[i1] = np.mean(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            signals_stds[i1] = np.std(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            # signals_means[i1] = np.mean(np.reshape(X[:,:,i1], (N_ist*seq_len)))
            # signals_stds[i1] = np.std(np.reshape(X[:,:,i1], (N_ist*seq_len)))

        # NORMALIZE THE SIGNALS    
        X_noise[:,:,i1] = (X_noise[:,:,i1] - signals_means[i1])/signals_stds[i1]
        # X[:,:,i1] = (X[:,:,i1] - signals_means[i1])/signals_stds[i1]
   
    # if path_data == path_data_train:    
    #     np.save(path_save+'Corrupted_signals_means', signals_means)
    #     np.save(path_save+'Corrupted_signals_stds', signals_stds)
       
    # return X_noise, labels_class, N_ist
    return X_noise, labels_class, N_ist


#Read data and create dataset adding more noise
def read_data_rumored(path_data, addedd_SNR):    
    label_path_class = path_data + '/Damage_class.csv'                                
    labels_class     = np.genfromtxt(label_path_class)
    labels_class     = labels_class.astype('int')
    N_ist = len(labels_class)  

    if accelerations == 1:
        path_rec  = path_data + '/U2_concat_'
    elif accelerations == 0:
        path_rec  = path_data + '/U_concat_'

    if path_data == path_data_train:
        signals_means = np.zeros((n_channels))
        signals_stds = np.zeros((n_channels))
    else:
        signals_means = np.load(path_restore+'/Corrupted_signals_means.npy')
        signals_stds = np.load(path_restore+'/Corrupted_signals_stds.npy')

    # Create the dataset output structure
    X       = np.zeros((N_ist, seq_len, n_channels))   #(10000,200,8)
    X_noise = np.zeros((N_ist, seq_len, n_channels))

    for i1 in range(n_channels):

        path_data_var  = path_rec + str(which_channels[i1]) + '.csv'
        X_singledof = pd.read_csv(path_data_var, header=None).to_numpy()[:,0]

        for i2 in range(N_ist):
            # RESHAPE THE SIGNALS
            X[i2,:,i1] = X_singledof[1 + i2*(1+seq_len) : (i2+1)*(1+seq_len)]
            
            # CORRUPT THE SIGNALS
            rms_signal = RMS(X[i2,:,i1])
            dev_std    = rms_signal / np.sqrt(addedd_SNR)
            
            # Aggiungi la dipendenza della media da addedd_SNR
            # Puoi scegliere una relazione specifica, ad esempio, media proporzionale a addedd_SNR
            # Genera una media casuale per ogni segnale
            mean_noise = np.random.uniform(-rms_signal / addedd_SNR, rms_signal / addedd_SNR)

            # Crea la distribuzione normale con media variabile e deviazione standard
            sample = st.norm(mean_noise, dev_std)
            X_noise[i2,:,i1] = X[i2,:,i1] + sample.rvs(size=seq_len)
        
        if path_data == path_data_train:
            # COMPUTE STATISTICS FOR EACH CHANNEL
            signals_means[i1] = np.mean(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            signals_stds[i1] = np.std(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))

        # NORMALIZE THE SIGNALS    
        X_noise[:,:,i1] = (X_noise[:,:,i1] - signals_means[i1]) / signals_stds[i1]

   
    # if path_data == path_data_train:    
    #     np.save(path_save+'Corrupted_signals_means', signals_means)
    #     np.save(path_save+'Corrupted_signals_stds', signals_stds)
       
    # return X_noise, labels_class, N_ist
    return X_noise, labels_class, N_ist




"""
## Create a sampling layer
"""

class Sampling(layers.Layer):
    """Uses (z_mean, z_log_var) to sample z, the vector encoding a digit."""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.seed_generator = keras.random.SeedGenerator(1337)

    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = ops.shape(z_mean)[0]
        dim = ops.shape(z_mean)[1]
        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)
        return z_mean + ops.exp(0.5 * z_log_var) * epsilon



"""
## Using Matteo's architecture
"""

n_class = 8
latent_dim = 4

# Hyperparameters
validation_split = 0.20
batch_size = 32
n_epochs = 150  #250
early_stop_epochs=15
initial_lr = 1e-3
decay_length = 0.8
ratio_to_stop = 0.05

filter_1      = 32;   filter_2      = 64;   filter_3      = 32
kernel_size_1 = 25;   kernel_size_2 =  13;   kernel_size_3 = 7
neurons_4 = 64
neurons_5 = 16
attivaz_conv = 'tanh'
attivaz_mlp = 'tanh'
k_reg = 1e-3
b_reg = 1e-3
rate_drop = 0.05

"""
## Build the encoder 
"""

encoder_inputs  = layers.Input(shape=(seq_len, n_channels), name='Convolutional_inputs')
x = layers.Conv1D(filters=filter_1, kernel_size=kernel_size_1, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_1')(encoder_inputs)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)   #Gli strati Dropout vengono utilizzati per regolarizzare il modello durante l'addestramento, disattivando casualmente una frazione di neuroni. Questo aiuta a prevenire l'overfitting.

x = layers.Conv1D(filters=filter_2, kernel_size=kernel_size_2, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_2')(x)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1D(filters=filter_3, kernel_size=kernel_size_3, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_3')(x)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Flatten()(x)

x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(x)
x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)

z_mean = layers.Dense(latent_dim, activation=None, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='z_mean')(x)
z_log_var = layers.Dense(latent_dim, activation=None, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='z_log_var')(x)
z = Sampling()([z_mean, z_log_var])

# Definisci il modello
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
encoder.summary()

"""
## Build the decoder 
"""

latent_inputs_decoder = layers.Input(shape=(latent_dim,), name='Latent_inputs')

x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1_decoder')(latent_inputs_decoder)
x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2_decoder')(x)
x = layers.Dense(units=filter_3 * (seq_len // 8), activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3_decoder')(x)
x = layers.Reshape((seq_len // 8, filter_3))(x)

# Applica strati Conv1DTranspose (o Conv1D per upsampling)
x = layers.Conv1DTranspose(filters=filter_3, kernel_size=kernel_size_3, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_1')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1DTranspose(filters=filter_2, kernel_size=kernel_size_2, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_2')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1DTranspose(filters=filter_1, kernel_size=kernel_size_1, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_3')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

# Ultimo livello per tornare alla forma originale
decoder_outputs = layers.Conv1D(filters=n_channels, kernel_size=kernel_size_1, activation=None, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Conv_1_decoder')(x)

# Definisci il modello
decoder = keras.Model(latent_inputs_decoder, decoder_outputs, name='decoder')
decoder.summary()




"""
## Build the Dense layer
"""

latent_inputs_classifier = layers.Input(shape=(latent_dim,), name='Latent_inputs')

x = layers.Dense(units=64, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(latent_inputs_classifier)
x = layers.Dense(units=32, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)
Dense_output = layers.Dense(n_class,activation=keras.activations.softmax,kernel_regularizer=regularizers.l2(k_reg),bias_regularizer=regularizers.l2(b_reg),name='Dense_3_with_Softmax')(x)

# Definisci il modello
classifier = keras.Model(latent_inputs_classifier, Dense_output, name='classifier')
classifier.summary()





"""
## Define the VAE class
"""

class VAE(keras.Model):
    def __init__(self, encoder, decoder, classifier,**kwargs):
        super().__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.classifier = classifier
        self.total_loss_tracker = keras.metrics.Mean(name="total_loss")
        self.reconstruction_loss_tracker = keras.metrics.Mean(name="reconstruction_loss")
        self.kl_loss_tracker = keras.metrics.Mean(name="kl_loss")
        self.classification_loss_tracker = keras.metrics.Mean(name="classification_loss")

    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
        ]

    def train_step(self, data):

        observations, damage_class_labels = data


        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(observations)

            reconstruction = self.decoder(z)

            # Predizione per la classificazione
            classification_preds = self.classifier(z)

            reconstruction_loss = ops.mean(
                ops.sum(
                    # keras.losses.binary_crossentropy(observations, reconstruction), #La funzione keras.losses.binary_crossentropy(data, reconstruction) restituisce un tensore bidimensionale di forma (batch_size, time_steps). 
                                                                                      #Questo avviene perché binary_crossentropy calcola la perdita per ogni time step, non per ogni canale.
                    keras.losses.mean_squared_error(observations, reconstruction),  # Calcola la perdita MSE tra dati originali e ricostruiti
                    axis=1,   
                )
            )
            
            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))
            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))

            # Perdita di classificazione (categorical crossentropy)
            classification_loss = keras.losses.sparse_categorical_crossentropy(damage_class_labels, classification_preds)
            classification_loss = tf.reduce_mean(classification_loss)

            beta = 1.0
            gamma = 60.0
            total_loss = reconstruction_loss + beta * kl_loss + gamma * classification_loss

        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))

        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        self.classification_loss_tracker.update_state(classification_loss)
        return {
            "loss": self.total_loss_tracker.result(),
            "reconstruction_loss": self.reconstruction_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
            "classification_loss": self.classification_loss_tracker.result(),
        }
    
    
    def test_step(self, data):
        observations, damage_class_labels = data
        z_mean, z_log_var, z = self.encoder(observations)
        reconstruction = self.decoder(z)
        classification_preds = self.classifier(z)

        # Calcolo della perdita per il test
        reconstruction_loss = ops.mean(
            ops.sum(
                # keras.losses.binary_crossentropy(data, reconstruction), #La funzione keras.losses.binary_crossentropy(data, reconstruction) restituisce un tensore bidimensionale di forma (batch_size, time_steps). 
                                                                          #Questo avviene perché binary_crossentropy calcola la perdita per ogni time step, non per ogni canale.
                keras.losses.mean_squared_error(observations, reconstruction),  # Calcola la perdita MSE tra dati originali e ricostruiti
                axis=1,   
                )
            )
        
        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)
        kl_loss = tf.reduce_mean(kl_loss)

        classification_loss = keras.losses.sparse_categorical_crossentropy(damage_class_labels, classification_preds)
        classification_loss = tf.reduce_mean(classification_loss)

        beta = 1.0
        gamma = 60.0
        total_loss = reconstruction_loss + beta * kl_loss + gamma * classification_loss

        return {
            "loss": total_loss,
            "reconstruction_loss": reconstruction_loss,
            "kl_loss": kl_loss,
            "classification_loss": classification_loss,
        }
    
    
    def call(self, inputs):
        # Passaggio attraverso l'encoder
        z_mean, z_log_var, z = self.encoder(inputs)
        
        # Decodifica del campione z
        reconstructed = self.decoder(z)

        # Decodifica del campione z
        classified = self.classifier(z)
        
        return reconstructed, classified




"""
## Funzioni utili
"""


def plot_label_clusters(vae, data, labels):
    # display a 2D plot of the digit classes in the latent space
    z_mean, _, _ = vae.encoder.predict(data, verbose=0)

    print(f"Forma di z_mean: {z_mean.shape}")
    print(f"Primi elementi di z_mean:\n{z_mean[0:4,:]}")

    plt.figure(figsize=(12, 10))
    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)
    plt.colorbar()
    plt.xlabel("z_mean[0]")
    plt.ylabel("z_mean[1]")
    # Imposta il titolo della figura
    plt.suptitle(f'Grouped by damage class', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_2d.png"))
    plt.close()




def plot_label_clusters_3d(vae, data, labels):
    # display a 3D plot of the digit classes in the latent space
    z_mean, _, _ = vae.encoder.predict(data, verbose=0)

    print(f"Forma di z_mean: {z_mean.shape}")
    print(f"Primi elementi di z_mean:\n{z_mean[0:4,:]}")

    if z_mean.shape[1] < 3:
        print("Attenzione: z_mean ha meno di 3 dimensioni. Potrebbe non essere possibile creare un grafico 3D.")
        return
    

    # Plot using nothing
    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')
    scatter = ax.scatter(z_mean[:, 0], z_mean[:, 1], z_mean[:, 2], c=labels, cmap='viridis')
    color_bar = fig.colorbar(scatter, ax=ax)
    color_bar.set_label('Classi')
    ax.set_xlabel("z_mean[0]")
    ax.set_ylabel("z_mean[1]")
    ax.set_zlabel("z_mean[2]")
    plt.suptitle(f'Grouped by damage class in 3D latent space', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_3d.png"))
    plt.show()


    # Plot using MDS
    mds = MDS(n_components=3)
    z_mds = mds.fit_transform(z_mean)

    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')
    scatter = ax.scatter(z_mds[:, 0], z_mds[:, 1], z_mds[:, 2], c=labels, cmap='viridis')
    color_bar = fig.colorbar(scatter, ax=ax)
    color_bar.set_label('Classi')
    ax.set_xlabel("MDS[0]")
    ax.set_ylabel("MDS[1]")
    ax.set_zlabel("MDS[2]")
    plt.suptitle(f'Grouped by damage class in 3D latent space using MDS', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_mds_3d.png"))
    plt.show()

    # Plot using TSNE  (in teoria serve più che altro se hai input categoriale)
    tsne = TSNE(n_components=3)
    z_tsne = tsne.fit_transform(z_mean)

    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')
    scatter = ax.scatter(z_tsne[:, 0], z_tsne[:, 1], z_tsne[:, 2], c=labels, cmap='viridis')
    color_bar = fig.colorbar(scatter, ax=ax)
    color_bar.set_label('Classi')
    ax.set_xlabel("TSNE[0]")
    ax.set_ylabel("TSNE[1]")
    ax.set_zlabel("TSNE[2]")
    plt.suptitle(f'Grouped by damage class in 3D latent space using TSNE', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_tsne_3d.png"))
    plt.show()

    # Plot using PCA
    pca = PCA(n_components=3)
    z_pca = pca.fit_transform(z_mean)

    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')
    scatter = ax.scatter(z_pca[:, 0], z_pca[:, 1], z_pca[:, 2], c=labels, cmap='viridis')
    color_bar = fig.colorbar(scatter, ax=ax)
    color_bar.set_label('Classi')
    ax.set_xlabel("PCA[0]")
    ax.set_ylabel("PCA[1]")
    ax.set_zlabel("PCA[2]")
    plt.suptitle(f'Grouped by damage class in 3D latent space using PCA', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_pca_3d.png"))
    plt.show()




def plot_variances_by_class(vae, data1, data2, data3):
    # Estrai z_log_var per ciascun dataset
    _, z_log_var1, _ = vae.encoder.predict(data1, verbose=0)
    _, z_log_var2, _ = vae.encoder.predict(data2, verbose=0)
    _, z_log_var3, _ = vae.encoder.predict(data3, verbose=0)

    X_test_reconstructed_1, X_test_classified_1 = vae.predict(data1)
    X_test_reconstructed_2, X_test_classified_2 = vae.predict(data2)
    X_test_reconstructed_3, X_test_classified_3 = vae.predict(data3)

    predicted_classes_1 = np.argmax(X_test_classified_1, axis=1)
    predicted_classes_2 = np.argmax(X_test_classified_1, axis=1)
    predicted_classes_3 = np.argmax(X_test_classified_1, axis=1)


    # Calcola le varianze dallo z_log_var
    variances1 = np.exp(z_log_var1)
    variances2 = np.exp(z_log_var2)
    variances3 = np.exp(z_log_var3)

    # Crea una figura con 8 sottografi (2x4 griglia)
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    axes = axes.flatten()

    # Plotta per ciascuna classe
    for i in range(n_class):
        # Seleziona i dati appartenenti alla classe i per ciascun dataset
        class_indices_1 = np.where(predicted_classes_1 == i)[0]
        class_indices_2 = np.where(predicted_classes_2 == i)[0]
        class_indices_3 = np.where(predicted_classes_3 == i)[0]
        
        # Estrai le varianze per ciascuna classe in ciascun dataset
        class_variances1 = variances1[class_indices_1]
        class_variances2 = variances2[class_indices_2]
        class_variances3 = variances3[class_indices_3]

        # # Plotta i 3 istogrammi sovrapposti (uno per ciascun dataset)
        # if len(class_variances1) > 0:
        #     axes[i].hist(class_variances1.flatten(), bins=30, alpha=0.5, color='blue', edgecolor='black', label='Data1 = meno rumoroso')
        # if len(class_variances2) > 0:
        #     axes[i].hist(class_variances2.flatten(), bins=30, alpha=0.5, color='orange', edgecolor='black', label='Data2 = medio rumoroso')
        # if len(class_variances3) > 0:
        #     axes[i].hist(class_variances3.flatten(), bins=30, alpha=0.5, color='green', edgecolor='black', label='Data3 = più rumoroso')

        # Plotta le curve di densità per ciascun dataset (KDE)
        if len(class_variances1) > 0:
            sns.kdeplot(class_variances1.flatten(), ax=axes[i], color='blue', label='Data1 = meno rumoroso')
        if len(class_variances2) > 0:
            sns.kdeplot(class_variances2.flatten(), ax=axes[i], color='orange', label='Data2 = medio rumoroso')
        if len(class_variances3) > 0:
            sns.kdeplot(class_variances3.flatten(), ax=axes[i], color='green', label='Data3 = più rumoroso')
        
        # Titolo per ciascun sottografo
        axes[i].set_title(f'Class {i} Variance Distribution')

        # Etichette per gli assi
        axes[i].set_xlabel('Variance')
        axes[i].set_ylabel('Frequency')
        
        # Aggiungi legenda
        axes[i].legend()

    # Aggiusta la spaziatura tra i sottografi
    plt.tight_layout()

    # Salva il grafico come file
    plt.savefig('output_VAE_1D/class_variance_histograms.png')

    # Mostra il grafico
    plt.show()




def plot_means_by_class(vae, data1, data2, data3):
    # Estrai z_mean per ciascun dataset
    z_mean1, _, _ = vae.encoder.predict(data1, verbose=0)
    z_mean2, _, _ = vae.encoder.predict(data2, verbose=0)
    z_mean3, _, _ = vae.encoder.predict(data3, verbose=0)

    X_test_reconstructed_1, X_test_classified_1 = vae.predict(data1)
    X_test_reconstructed_2, X_test_classified_2 = vae.predict(data2)
    X_test_reconstructed_3, X_test_classified_3 = vae.predict(data3)

    predicted_classes_1 = np.argmax(X_test_classified_1, axis=1)
    predicted_classes_2 = np.argmax(X_test_classified_2, axis=1)
    predicted_classes_3 = np.argmax(X_test_classified_3, axis=1)

    # Crea una figura con 8 sottografi (2x4 griglia)
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    axes = axes.flatten()

    # Plotta per ciascuna classe
    for i in range(n_class):
        # Seleziona i dati appartenenti alla classe i per ciascun dataset
        class_indices_1 = np.where(predicted_classes_1 == i)[0]
        class_indices_2 = np.where(predicted_classes_2 == i)[0]
        class_indices_3 = np.where(predicted_classes_3 == i)[0]

        # Estrai le medie per ciascuna classe in ciascun dataset
        class_means1 = z_mean1[class_indices_1]
        class_means2 = z_mean2[class_indices_2]
        class_means3 = z_mean3[class_indices_3]

        # Plotta le curve di densità per ciascun dataset (KDE)
        if len(class_means1) > 0:
            sns.kdeplot(class_means1.flatten(), ax=axes[i], color='blue', label='Data1 = meno rumoroso')
        if len(class_means2) > 0:
            sns.kdeplot(class_means2.flatten(), ax=axes[i], color='orange', label='Data2 = medio rumoroso')
        if len(class_means3) > 0:
            sns.kdeplot(class_means3.flatten(), ax=axes[i], color='green', label='Data3 = più rumoroso')

        # Titolo per ciascun sottografo
        axes[i].set_title(f'Class {i} Mean Distribution')

        # Etichette per gli assi
        axes[i].set_xlabel('Mean')
        axes[i].set_ylabel('Density')

        # Aggiungi legenda
        axes[i].legend()

    # Aggiusta la spaziatura tra i sottografi
    plt.tight_layout()

    # Salva il grafico come file
    plt.savefig('output_VAE_1D/class_mean_histograms.png')

    # Mostra il grafico
    plt.show()






def plot_class_transition_heatmap(vae, data1, data2):
    # Prevedi le classi per i due dataset
    X_test_reconstructed_1, X_test_classified_1 = vae.predict(data1)
    X_test_reconstructed_2, X_test_classified_2 = vae.predict(data2)

    # Predici le classi (argmax lungo l'asse delle classi)
    predicted_classes_1 = np.argmax(X_test_classified_1, axis=1)
    predicted_classes_2 = np.argmax(X_test_classified_2, axis=1)

    #Plot differenza di un signal random
    idx = np.random.randint(0, X_test.shape[0])
    original_signal = data1[idx]
    reconstructed_signal = data2[idx]

    # Calcola la differenza tra il segnale originale e quello ricostruito
    difference_signal = original_signal - reconstructed_signal

    plt.figure(figsize=(10, 6))

    # Plot del segnale originale con trasparenza
    plt.plot(original_signal.flatten(), label='Meno rumoroso', color='blue', alpha=0.5)

    # Plot del segnale ricostruito con trasparenza
    plt.plot(reconstructed_signal.flatten(), label='Più rumoroso', color='orange', alpha=0.5)

    # Plot della differenza tra i due segnali (linea piena e nera)
    plt.plot(difference_signal.flatten(), label='Differenza', color='black')

    plt.legend()
    plt.title(f"Segnale Meno Rumore vs Segnale Più Rumore - Esempio {idx}")
    plt.show()

    # Costruisci la matrice di transizione (matrice di confusione tra le due predizioni)
    transition_matrix = confusion_matrix(predicted_classes_1, predicted_classes_2, labels=np.arange(n_class))

    # Plotta la matrice di transizione come heatmap
    plt.figure(figsize=(10, 8))
    sns.heatmap(transition_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.arange(n_class), yticklabels=np.arange(n_class))
    
    # Etichette e titolo
    plt.title("Class Transition Matrix (Data1 vs Data2)", fontsize=16)
    plt.xlabel("Predicted Class (Data2)", fontsize=12)
    plt.ylabel("Predicted Class (Data1)", fontsize=12)

    # Salva la figura
    plt.savefig('output_VAE_1D/class_transition_heatmap.png')

    # Mostra il grafico
    plt.show()



def variation_mean_and_var(vae, data1, data2):
    # Prevedi z_mean e z_log_var per i due dataset
    z_mean1, z_log_var1, _ = vae.encoder.predict(data1, verbose=0)
    z_mean2, z_log_var2, _ = vae.encoder.predict(data2, verbose=0)

    # Prevedi le classi per i due dataset
    X_test_reconstructed_1, X_test_classified_1 = vae.predict(data1)
    X_test_reconstructed_2, X_test_classified_2 = vae.predict(data2)

    # Predici le classi (argmax lungo l'asse delle classi)
    predicted_classes_1 = np.argmax(X_test_classified_1, axis=1)
    predicted_classes_2 = np.argmax(X_test_classified_2, axis=1)

    # Trova le classi comuni tra i due dataset
    classes = np.unique(predicted_classes_1)

    results = []

    # Ciclo attraverso ogni classe comune
    for c in classes:
        # Indici degli esempi che appartengono alla classe c nel primo e secondo dataset
        idx1 = predicted_classes_1 == c
        idx2 = predicted_classes_2 == c

        # Seleziona i dati z_mean e z_log_var per la classe c
        z_mean1_class = z_mean1[idx1]
        z_mean2_class = z_mean2[idx2]
        z_log_var1_class = z_log_var1[idx1]
        z_log_var2_class = z_log_var2[idx2]

        # Calcola la differenza tra le medie e le varianze per la classe c
        mean_diff_class = np.mean(z_mean1_class, axis=0) - np.mean(z_mean2_class, axis=0)
        var_diff_class = np.mean(z_log_var1_class, axis=0) - np.mean(z_log_var2_class, axis=0)

        # Calcolo della percentuale di variazione
        mean_diff_percent_class = (mean_diff_class / (np.mean(np.abs(z_mean1_class), axis=0) + 1e-9)) * 100
        var_diff_percent_class = (var_diff_class / (np.mean(np.abs(z_log_var1_class), axis=0) + 1e-9)) * 100

        # Salva i risultati per la classe c
        results.append({
            "Class": c,
            "Mean Diff Abs": np.mean(mean_diff_class),
            "Var Diff Abs": np.mean(var_diff_class),
            "Mean Diff %": np.mean(mean_diff_percent_class),
            "Var Diff %": np.mean(var_diff_percent_class)
        })

    # Calcolo complessivo su tutti i dati
    mean_diff_total = np.mean(z_mean1, axis=0) - np.mean(z_mean2, axis=0)
    var_diff_total = np.mean(z_log_var1, axis=0) - np.mean(z_log_var2, axis=0)
    
    mean_diff_percent_total = (mean_diff_total / (np.mean(np.abs(z_mean1), axis=0) + 1e-9)) * 100
    var_diff_percent_total = (var_diff_total / (np.mean(np.abs(z_log_var1), axis=0) + 1e-9)) * 100

    # Aggiungi i risultati totali
    results.append({
        "Class": "Total",
        "Mean Diff Abs": np.mean(mean_diff_total),
        "Var Diff Abs": np.mean(var_diff_total),
        "Mean Diff %": np.mean(mean_diff_percent_total),
        "Var Diff %": np.mean(var_diff_percent_total)
    })

    # Salva i risultati formattati in un file di testo
    with open('output_VAE_1D/variation_results.txt', 'w') as f:
        f.write(f"{'Class':<15} {'Mean Diff Abs':<20} {'Var Diff Abs':<20} {'Mean Diff %':<20} {'Var Diff %':<20}\n")
        f.write("-" * 95 + "\n")
        for result in results:
            f.write(f"{result['Class']:<15} {result['Mean Diff Abs']:<20.5f} {result['Var Diff Abs']:<20.5f} "
                    f"{result['Mean Diff %']:<20.2f} {result['Var Diff %']:<20.2f}\n")

    # Trasforma i risultati in un DataFrame Pandas per una migliore visualizzazione
    df = pd.DataFrame(results)
    return df




def plot_confidence_histogram(probabilities):
    # Prendi la probabilità massima per ciascuna predizione
    max_probabilities = np.max(probabilities, axis=1)
    
    # Plot dell'istogramma
    plt.figure(figsize=(8, 6))
    plt.hist(max_probabilities, bins=50, range=(0, 1), alpha=0.7, color='b')
    plt.title('Istogramma della confidenza delle previsioni')
    plt.xlabel('Confidenza (probabilità massima)')
    plt.ylabel('Frequenza')
    plt.grid(True)
    plt.show()

def plot_confidence_histogram_per_class(probabilities, predicted_labels):
    # Creiamo una figura con 8 sottotrame (2 righe x 4 colonne)
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    axes = axes.ravel()  # Rende il grid facilmente accessibile con un array 1D

    for i in range(n_class):
        # Filtra le probabilità per la classe vera i
        class_probabilities = probabilities[predicted_labels == i]
        max_probabilities = np.max(class_probabilities, axis=1)
        
        # Plot dell'istogramma nella sottotrama i
        axes[i].hist(max_probabilities, bins=50, range=(0, 1), alpha=0.7, color='b')
        axes[i].set_title(f'Classe {i}')
        axes[i].set_xlabel('Confidenza (probabilità massima)')
        axes[i].set_ylabel('Frequenza')
        axes[i].grid(True)
    
    # Aggiustiamo lo spazio tra le sottotrame
    plt.tight_layout()
    plt.show()





def plot_margin_histogram(probabilities):
    # Ordina le probabilità in ordine decrescente lungo l'asse delle classi
    sorted_probabilities = np.sort(probabilities, axis=1)
    
    # Differenza tra la prima e la seconda probabilità più alta
    margin = sorted_probabilities[:, -1] - sorted_probabilities[:, -2]
    
    # Plot dell'istogramma del margine
    plt.figure(figsize=(8, 6))
    plt.hist(margin, bins=50, range=(0, 1), alpha=0.7, color='g')
    plt.title('Istogramma del margine tra prima e seconda probabilità più alta')
    plt.xlabel('Margine di confidenza')
    plt.ylabel('Frequenza')
    plt.grid(True)
    plt.show()

def plot_margin_histogram_per_class(probabilities, predicted_labels):
    # Creiamo una figura con 8 sottotrame (2 righe x 4 colonne)
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    axes = axes.ravel()  # Rende il grid facilmente accessibile con un array 1D

    for i in range(n_class):
        # Filtra le probabilità per la classe vera i
        class_probabilities = probabilities[predicted_labels == i]
        sorted_probabilities = np.sort(class_probabilities, axis=1)
        
        # Differenza tra la prima e la seconda probabilità più alta
        margin = sorted_probabilities[:, -1] - sorted_probabilities[:, -2]
        
        # Plot dell'istogramma nella sottotrama i
        axes[i].hist(margin, bins=50, range=(0, 1), alpha=0.7, color='g')
        axes[i].set_title(f'Classe {i}')
        axes[i].set_xlabel('Margine di confidenza')
        axes[i].set_ylabel('Frequenza')
        axes[i].grid(True)
    
    # Aggiustiamo lo spazio tra le sottotrame
    plt.tight_layout()
    plt.show()


    


def plot_roc_curve(true_labels, probabilities):
    # Binarizza le etichette reali per il calcolo multi-classe
    true_labels_bin = label_binarize(true_labels, classes=np.arange(n_class))
    
    # Plot della curva ROC per ogni classe
    plt.figure(figsize=(10, 8))
    for i in range(n_class):
        fpr, tpr, _ = roc_curve(true_labels_bin[:, i], probabilities[:, i])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f'Classe {i} (AUC = {roc_auc:.2f})')
    
    plt.plot([0, 1], [0, 1], 'k--')  # Linea diagonale di random guess
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Curva ROC multi-classe')
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.show()

    # Calcola l'AUC medio
    auc_score = roc_auc_score(true_labels_bin, probabilities, average="macro", multi_class="ovr")
    print(f'AUC medio: {auc_score:.2f}')




def visualize_latent_space(z_mean, true_labels, predicted_clusters, method='pca'):

    # Seleziona il riduttore di dimensionalità
    if method == 'pca':
        reducer = PCA(n_components=2)
    elif method == 'tsne':
        reducer = TSNE(n_components=2, perplexity=30, learning_rate=200)
    
    z_reduced = reducer.fit_transform(z_mean)
    
    # Crea una figura con due sotto-figure
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 7))

    # Primo plot con le true labels
    sns.scatterplot(x=z_reduced[:, 0], y=z_reduced[:, 1], hue=true_labels, palette="tab10", s=60, alpha=0.7, ax=ax1)
    ax1.set_title(f'Latent Space Visualization using {method.upper()} (True Labels)')
    ax1.set_xlabel('Component 1')
    ax1.set_ylabel('Component 2')

    # Secondo plot con i predicted clusters
    sns.scatterplot(x=z_reduced[:, 0], y=z_reduced[:, 1], hue=predicted_clusters, palette="tab10", s=60, alpha=0.7, ax=ax2)
    ax2.set_title(f'Latent Space Visualization using {method.upper()} (Predicted Clusters)')
    ax2.set_xlabel('Component 1')
    ax2.set_ylabel('Component 2')

    # Mostra i grafici
    plt.tight_layout()
    plt.show()

from sklearn.cluster import KMeans


def cluster_latent_space(data, true_labels):
    #Applica K-Means al latent space e confronta con le true labels.

    z_mean, _, _ = vae.encoder.predict(data, verbose=0)

    kmeans = KMeans(n_clusters=n_class)
    predicted_clusters = kmeans.fit_predict(z_mean)
    
    # Confronta i cluster predetti con le true labels (puoi usare metodi come accuracy, adjusted Rand index)
    print(f"Clustering accuracy: {accuracy_score(true_labels, predicted_clusters):.4f}")
    
    # Visualizza i cluster
    visualize_latent_space(z_mean, true_labels, predicted_clusters, method='pca')











train_or_predict = 0   # 1: training, 0: predict                                       


if train_or_predict:

    """
    ## Model training
    """

    observations_normalized, damage_class_labels, N_ist_train = read_data(path_data_train, 100)

    print(f"Forma di observations_normalized: {observations_normalized.shape}")

    for i in range(2):  
        print(f"Forma della {i+1}° osservazione: {observations_normalized[i].shape}")

    # Separare i dati in training e validation set
    train_observations, val_observations, train_labels, val_labels = train_test_split(observations_normalized, damage_class_labels, test_size=validation_split, random_state=42)

    # Creare dataset TensorFlow per il training
    train_dataset = tf.data.Dataset.from_tensor_slices((train_observations, train_labels))
    train_dataset = train_dataset.batch(batch_size)

    # Creare dataset TensorFlow per la validazione
    val_dataset = tf.data.Dataset.from_tensor_slices((val_observations, val_labels))
    val_dataset = val_dataset.batch(batch_size)

    vae = VAE(encoder, decoder, classifier)

    vae.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist_train*(1-validation_split)/batch_size), alpha=ratio_to_stop)))

    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stop_epochs, restore_best_weights=True)


    # Allenamento del modello
    history = vae.fit(train_dataset, epochs=n_epochs, validation_data=val_dataset, batch_size=batch_size, verbose=2, callbacks=[early_stop])



    # Salva lo storico dell'addestramento in formato pickle
    hist = pd.DataFrame(history.history)  # Converti history.history (dati storici dell'addestramento) in un DataFrame di pandas
    hist['epoch'] = history.epoch  # Aggiungi una colonna per le epoche. history.epoch è una lista che contiene i numeri delle epoche per cui sono stati registrati i dati.

    # Salva il DataFrame
    try:
        hist.to_pickle(os.path.join(path_save, 'hist_VAE_1D.pkl'))   #Salva il DataFrame hist in un file con formato pickle.
        print(f"Storico salvato in {os.path.join(path_save, 'hist_VAE_1D.pkl')}")
    except Exception as e:
        print(f"Errore durante il salvataggio dello storico: {e}")

    # Salva il modello
    try:
        vae.save(os.path.join(path_save, 'model_VAE_1D.keras'))   # Salva il modello vae addestrato in formato Keras
        print(f"Modello salvato in {os.path.join(path_save, 'model_VAE_1D.keras')}")
    except Exception as e:
        print(f"Errore durante il salvataggio del modello: {e}")

    # Salva i pesi
    vae.save_weights('./models/VAE_1D.weights.h5')


    """
    ## Output
    """

    # Crea la cartella se non esiste
    output_dir = "output_VAE_1D"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Plot combinato per la training loss e la validation loss
    plt.figure(figsize=(15, 5))  # Dimensioni del plot
    plt.plot(history.history["loss"], label="Training Loss", color='blue')
    plt.plot(history.history["val_loss"], label="Validation Loss", color='orange')
    plt.title("Training and Validation Loss")
    plt.ylabel("Loss")
    plt.xlabel("Epoch")
    plt.legend(loc="upper right")
    plt.grid(True)
    plt.savefig(os.path.join(output_dir, "losses.png"))
    plt.show()
    plt.close()


    # plot_label_clusters(vae, observations_normalized , damage_class_labels)
    plot_label_clusters_3d(vae, observations_normalized , damage_class_labels)


else:

    """
    ## Predict
    """

    # Caricamento dei dati di test
    X_test, labels_test, N_ist_test = read_data_rumored(path_data_test, 100)

    print(f"Forma di X_test: {X_test.shape}")

    # Creare dataset TensorFlow per il testing
    # test_dataset = tf.data.Dataset.from_tensor_slices((X_test, labels_test))
    # test_dataset = test_dataset.batch(batch_size)


    # Creazione dell'istanza VAE
    vae = VAE(encoder, decoder, classifier)
    vae.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist_test*(1-validation_split)/batch_size), alpha=ratio_to_stop)))

    # Caricamento dei pesi salvati
    vae.load_weights('./models/VAE_1D.weights.h5')


    # Ricostruzione dei dati di test
    X_test_reconstructed, X_test_classified = vae.predict(X_test)

    # Calcolo della perdita di ricostruzione (MSE tra dati originali e ricostruiti)
    reconstruction_loss = ops.mean(ops.sum(keras.losses.mean_squared_error(X_test, X_test_reconstructed), axis=1))

    # Caricamento della cronologia dell'addestramento
    hist = pd.read_pickle(path_save + 'hist_VAE_1D.pkl')

    # Ottieni le classi previste
    predicted_classes = np.argmax(X_test_classified, axis=1)


    output_dir = "output_VAE_1D"

    """
    ## Analisi della ricostruzione
    """

    # MSE e MAE tra i dati ricostruiti e originali
    mse_reconstruction = mean_squared_error(X_test.flatten(), X_test_reconstructed.flatten())
    mae_reconstruction = mean_absolute_error(X_test.flatten(), X_test_reconstructed.flatten())

    print(f"Mean Squared Error (MSE) sulla ricostruzione: {mse_reconstruction}")
    print(f"Mean Absolute Error (MAE) sulla ricostruzione: {mae_reconstruction}")


    # # Seleziona un esempio casuale
    # idx = np.random.randint(0, X_test.shape[0])
    # original_signal = X_test[idx]
    # reconstructed_signal = X_test_reconstructed[idx]

    # # Plot dei segnali
    # plt.plot(original_signal.flatten(), label='Originale')
    # plt.plot(reconstructed_signal.flatten(), label='Ricostruito')
    # plt.legend()
    # plt.title(f"Segnale Originale vs Ricostruito - Esempio {idx}")
    # plt.show()


    # Seleziona un esempio casuale
    # idx = np.random.randint(0, X_test.shape[0])
    # original_signal = X_test[idx]
    # reconstructed_signal = X_test_reconstructed[idx]

    # # Calcola la differenza tra il segnale originale e quello ricostruito
    # difference_signal = original_signal - reconstructed_signal

    # plt.figure(figsize=(10, 6))

    # # Plot del segnale originale con trasparenza
    # plt.plot(original_signal.flatten(), label='Originale', color='blue', alpha=0.5)

    # # Plot del segnale ricostruito con trasparenza
    # plt.plot(reconstructed_signal.flatten(), label='Ricostruito', color='orange', alpha=0.5)

    # # Plot della differenza tra i due segnali (linea piena e nera)
    # plt.plot(difference_signal.flatten(), label='Differenza', color='black')

    # plt.legend()
    # plt.title(f"Segnale Originale vs Ricostruito - Esempio {idx}")
    # plt.show()



    """
    ## Analisi della classificazione
    """

    # Calcola metriche di classificazione
    accuracy = accuracy_score(labels_test, predicted_classes)
    precision = precision_score(labels_test, predicted_classes, average='weighted')
    recall = recall_score(labels_test, predicted_classes, average='weighted')
    f1 = f1_score(labels_test, predicted_classes, average='weighted')

    # Calcola la matrice di confusione
    conf_matrix = confusion_matrix(labels_test, predicted_classes)

    # Crea una figura con due sotto-figure
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 14))

    # Plot della matrice di confusione
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax1)
    ax1.set_title('Confusion Matrix')
    ax1.set_xlabel('Predicted Label')
    ax1.set_ylabel('True Label')

    # Aggiungi le metriche di classificazione come testo nella seconda sotto-figura
    metrics_text = (
        f"Accuracy: {accuracy:.4f}\n"
        f"Precision: {precision:.4f}\n"
        f"Recall: {recall:.4f}\n"
        f"F1-Score: {f1:.4f}"
    )
    ax2.text(0.5, 0.5, metrics_text, fontsize=12, ha='center', va='center')
    ax2.set_axis_off()  # Nascondi gli assi

    # Salva il grafico
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "Confusion_Matrix_VAE.png"))

    # Mostra il grafico
    plt.show()



    """
    ## Analisi ulteriori
    """
    X_test_2, labels_test_2, N_ist_test_2 = read_data_rumored(path_data_test, 20)
    # test_dataset_2 = tf.data.Dataset.from_tensor_slices((X_test_2, labels_test_2))
    # test_dataset_2 = test_dataset_2.batch(batch_size)

    X_test_3, labels_test_3, N_ist_test_3 = read_data_rumored(path_data_test, 5)
    # test_dataset_3 = tf.data.Dataset.from_tensor_slices((X_test_3, labels_test_3))
    # test_dataset_3 = test_dataset_3.batch(batch_size)

    # plot_label_clusters_3d(vae, X_test, predicted_classes)   #Plotta il clustering rispetto al label classificato dei dati test nello spazio latente

    # plot_class_transition_heatmap(vae, X_test, X_test_2)   #Plotta transition_map da X_test_2 a X_test_3


    plot_variances_by_class(vae, X_test, X_test_2, X_test_3)  #Plotta densità variances per classe per i tre dataset
    plot_means_by_class(vae, X_test, X_test_2, X_test_3)    #Plotta densità variances per classe per i tre dataset

    df = variation_mean_and_var(vae, X_test_2, X_test_3)   #Restituisce file densità variances per classe per i due dataset
    

    # cluster_latent_space(X_test, labels_test)     #Confronta i cluster predetti con le true labels

     #Analisi sul softmax    
    # plot_confidence_histogram_per_class(X_test_classified, predicted_classes)  
    # plot_margin_histogram_per_class(X_test_classified, predicted_classes)

    # plot_roc_curve(labels_test, X_test_classified)   #Plotta roc curve per classe della classificazione ottenuta da X_test