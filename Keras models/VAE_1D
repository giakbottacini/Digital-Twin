"""
Title: Variational AutoEncoder
Author: [fchollet](https://twitter.com/fchollet)
Date created: 2020/05/03
Last modified: 2024/04/24
Description: Convolutional Variational AutoEncoder (VAE) trained on MNIST digits.
Accelerator: GPU
"""

"""
## Setup
"""

import os

os.environ["KERAS_BACKEND"] = "tensorflow"

import numpy as np
import tensorflow as tf
import keras
from keras import ops
from keras import layers
from keras import regularizers
from keras import losses
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as st

from sklearn.model_selection import train_test_split


#VAE for DT

# Specify the example you are dealing with
esempio = 'L_FRAME_DT'
# Training and Testing data
ID              = '7_1'
save_ID         = 'Classifier_total_7_1/'
path            = "../" + esempio + '/Dati/'
path_data_train   = path + 'istantrain_' + ID
path_data_test   = path + 'istantest_' + ID
# Saving model
path_save       = "models/"
# Prediction model
restore_ID= 'Classifier_total_7_1/'
path_restore = "models/"

# Which dof monitored
which_channels = [1,2,3,4,5,6,7,8]

n_channels = 8
seq_len = 200
addedd_SNR = 100
# Specify if you are using accelerations =1 or displacements =0
accelerations = 0

# Questa funzione calcola il valore quadratico medio (RMS) di un vettore di segnale, utile per misurare l'energia del segnale e per 
# aggiungere rumore durante la corruzione dei segnali.
def RMS(vect):
    return np.sqrt(np.mean(np.square(vect)))


# ----------------------------------------------------------------------------

"""
## Importazione dati
"""

# Read data and create dataset with only desired classes
def read_data(path_data):    
    label_path_class = path_data + '/Damage_class.csv'                                
    labels_class     = np.genfromtxt(label_path_class)
    labels_class     = labels_class.astype('int')
    N_ist = len(labels_class)  

    if accelerations == 1:
        path_rec  = path_data + '/U2_concat_'
    elif accelerations == 0:
        path_rec  = path_data + '/U_concat_'

    if path_data == path_data_train:
        signals_means = np.zeros((n_channels))
        signals_stds = np.zeros((n_channels))
    else:
        signals_means = np.load(path_restore+'/Corrupted_signals_means.npy')
        signals_stds = np.load(path_restore+'/Corrupted_signals_stds.npy')
    # Create the dataset output structure
    X = np.zeros((N_ist, seq_len, n_channels))   #(10000,200,8)
    X_noise = np.zeros((N_ist, seq_len, n_channels))
    for i1 in range(n_channels):
        path_data_var  = path_rec + str(which_channels[i1]) + '.csv'
        X_singledof = pd.read_csv(path_data_var, header=None).to_numpy()[:,0]
        for i2 in range(N_ist):
            # RESHAPE THE SIGNALS
            X[i2,:,i1]= X_singledof[1 + i2*(1+seq_len) : (i2+1)*(1+seq_len)]
            # # CORRUPT THE SIGNALS
            rms_signal = RMS(X[i2,:,i1])
            dev_std    = rms_signal / np.sqrt(addedd_SNR)
            sample = st.norm(0, dev_std)
            X_noise[i2,:,i1] = X[i2,:,i1] + sample.rvs(size=seq_len)
        if path_data == path_data_train:
            # COMPUTE STATISTICS FOR EACH CHANNEL
            signals_means[i1] = np.mean(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            signals_stds[i1] = np.std(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            # signals_means[i1] = np.mean(np.reshape(X[:,:,i1], (N_ist*seq_len)))
            # signals_stds[i1] = np.std(np.reshape(X[:,:,i1], (N_ist*seq_len)))

        # NORMALIZE THE SIGNALS    
        X_noise[:,:,i1] = (X_noise[:,:,i1] - signals_means[i1])/signals_stds[i1]
        # X[:,:,i1] = (X[:,:,i1] - signals_means[i1])/signals_stds[i1]
   
    # if path_data == path_data_train:    
    #     np.save(path_save+'Corrupted_signals_means', signals_means)
    #     np.save(path_save+'Corrupted_signals_stds', signals_stds)
       
    # return X_noise, labels_class, N_ist
    return X_noise, labels_class, N_ist


"""
## Create a sampling layer
"""

class Sampling(layers.Layer):
    """Uses (z_mean, z_log_var) to sample z, the vector encoding a digit."""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.seed_generator = keras.random.SeedGenerator(1337)

    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = ops.shape(z_mean)[0]
        dim = ops.shape(z_mean)[1]
        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)
        return z_mean + ops.exp(0.5 * z_log_var) * epsilon



"""
## Using Matteo's architecture
"""

n_class = 8
latent_dim = 4

# Hyperparameters
validation_split = 0.20
batch_size = 32
n_epochs = 150  #250
early_stop_epochs=15
initial_lr = 1e-3
decay_length = 0.8
ratio_to_stop = 0.05

filter_1      = 32;   filter_2      = 64;   filter_3      = 32
kernel_size_1 = 25;   kernel_size_2 =  13;   kernel_size_3 = 7
neurons_4 = 64
neurons_5 = 16
attivaz_conv = 'tanh'
attivaz_mlp = 'tanh'
k_reg = 1e-3
b_reg = 1e-3
rate_drop = 0.05

"""
## Build the encoder 
"""

encoder_inputs  = layers.Input(shape=(seq_len, n_channels), name='Convolutional_inputs')
x = layers.Conv1D(filters=filter_1, kernel_size=kernel_size_1, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_1')(encoder_inputs)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)   #Gli strati Dropout vengono utilizzati per regolarizzare il modello durante l'addestramento, disattivando casualmente una frazione di neuroni. Questo aiuta a prevenire l'overfitting.

x = layers.Conv1D(filters=filter_2, kernel_size=kernel_size_2, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_2')(x)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1D(filters=filter_3, kernel_size=kernel_size_3, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_3')(x)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Flatten()(x)

x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(x)
x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)

z_mean = layers.Dense(latent_dim, activation=None, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='z_mean')(x)
z_log_var = layers.Dense(latent_dim, activation=None, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='z_log_var')(x)
z = Sampling()([z_mean, z_log_var])

# Definisci il modello
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
encoder.summary()

"""
## Build the decoder 
"""

latent_inputs_decoder = layers.Input(shape=(latent_dim,), name='Latent_inputs')

x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1_decoder')(latent_inputs_decoder)
x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2_decoder')(x)
x = layers.Dense(units=filter_3 * (seq_len // 8), activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3_decoder')(x)
x = layers.Reshape((seq_len // 8, filter_3))(x)

# Applica strati Conv1DTranspose (o Conv1D per upsampling)
x = layers.Conv1DTranspose(filters=filter_3, kernel_size=kernel_size_3, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_1')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1DTranspose(filters=filter_2, kernel_size=kernel_size_2, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_2')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1DTranspose(filters=filter_1, kernel_size=kernel_size_1, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_3')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

# Ultimo livello per tornare alla forma originale
decoder_outputs = layers.Conv1D(filters=n_channels, kernel_size=kernel_size_1, activation=None, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Conv_1_decoder')(x)

# Definisci il modello
decoder = keras.Model(latent_inputs_decoder, decoder_outputs, name='decoder')
decoder.summary()




"""
## Build the Dense layer
"""

latent_inputs_classifier = layers.Input(shape=(latent_dim,), name='Latent_inputs')

x = layers.Dense(units=64, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(latent_inputs_classifier)
x = layers.Dense(units=32, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)
Dense_output = layers.Dense(n_class,activation=keras.activations.softmax,kernel_regularizer=regularizers.l2(k_reg),bias_regularizer=regularizers.l2(b_reg),name='Dense_3_with_Softmax')(x)

# Definisci il modello
classifier = keras.Model(latent_inputs_classifier, Dense_output, name='decoder')
classifier.summary()





"""
## Define the VAE class
"""

class VAE(keras.Model):
    def __init__(self, encoder, decoder, classifier,**kwargs):
        super().__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.classifier = classifier
        self.total_loss_tracker = keras.metrics.Mean(name="total_loss")
        self.reconstruction_loss_tracker = keras.metrics.Mean(name="reconstruction_loss")
        self.kl_loss_tracker = keras.metrics.Mean(name="kl_loss")
        self.classification_loss_tracker = keras.metrics.Mean(name="classification_loss")

    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
        ]

    def train_step(self, data):

        observations, damage_class_labels = data


        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(observations)

            reconstruction = self.decoder(z)

            # Predizione per la classificazione
            classification_preds = self.classifier(z)

            reconstruction_loss = ops.mean(
                ops.sum(
                    # keras.losses.binary_crossentropy(observations, reconstruction), #La funzione keras.losses.binary_crossentropy(data, reconstruction) restituisce un tensore bidimensionale di forma (batch_size, time_steps). 
                                                                                      #Questo avviene perché binary_crossentropy calcola la perdita per ogni time step, non per ogni canale.
                    keras.losses.mean_squared_error(observations, reconstruction),  # Calcola la perdita MSE tra dati originali e ricostruiti
                    axis=1,   
                )
            )
            
            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))
            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))

            # Perdita di classificazione (categorical crossentropy)
            classification_loss = keras.losses.sparse_categorical_crossentropy(damage_class_labels, classification_preds)
            classification_loss = tf.reduce_mean(classification_loss)

            beta = 1.0
            gamma = 60.0
            total_loss = reconstruction_loss + beta * kl_loss + gamma * classification_loss

        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))

        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        self.classification_loss_tracker.update_state(classification_loss)
        return {
            "loss": self.total_loss_tracker.result(),
            "reconstruction_loss": self.reconstruction_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
            "classification_loss": self.classification_loss_tracker.result(),
        }
    
    
    def test_step(self, data):
        observations, damage_class_labels = data
        z_mean, z_log_var, z = self.encoder(observations)
        reconstruction = self.decoder(z)
        classification_preds = self.classifier(z)

        # Calcolo della perdita per il test
        reconstruction_loss = ops.mean(
            ops.sum(
                # keras.losses.binary_crossentropy(data, reconstruction), #La funzione keras.losses.binary_crossentropy(data, reconstruction) restituisce un tensore bidimensionale di forma (batch_size, time_steps). 
                                                                          #Questo avviene perché binary_crossentropy calcola la perdita per ogni time step, non per ogni canale.
                keras.losses.mean_squared_error(observations, reconstruction),  # Calcola la perdita MSE tra dati originali e ricostruiti
                axis=1,   
                )
            )
        
        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)
        kl_loss = tf.reduce_mean(kl_loss)

        classification_loss = keras.losses.sparse_categorical_crossentropy(damage_class_labels, classification_preds)
        classification_loss = tf.reduce_mean(classification_loss)

        beta = 1.0
        gamma = 60.0
        total_loss = reconstruction_loss + beta * kl_loss + gamma * classification_loss

        return {
            "loss": total_loss,
            "reconstruction_loss": reconstruction_loss,
            "kl_loss": kl_loss,
            "classification_loss": classification_loss,
        }
    
    
    def call(self, inputs):
        # Passaggio attraverso l'encoder
        z_mean, z_log_var, z = self.encoder(inputs)
        
        # Decodifica del campione z
        reconstructed = self.decoder(z)

        # Decodifica del campione z
        classified = self.classifier(z)
        
        return reconstructed, classified




"""
## Model training
"""

observations_normalized, damage_class_labels, N_ist_train = read_data(path_data_train)

print(f"Forma di observations_normalized: {observations_normalized.shape}")

for i in range(2):  
    print(f"Forma della {i+1}° osservazione: {observations_normalized[i].shape}")

# Separare i dati in training e validation set
train_observations, val_observations, train_labels, val_labels = train_test_split(observations_normalized, damage_class_labels, test_size=validation_split, random_state=42)

# Creare dataset TensorFlow per il training
train_dataset = tf.data.Dataset.from_tensor_slices((train_observations, train_labels))
train_dataset = train_dataset.batch(batch_size)

# Creare dataset TensorFlow per la validazione
val_dataset = tf.data.Dataset.from_tensor_slices((val_observations, val_labels))
val_dataset = val_dataset.batch(batch_size)

vae = VAE(encoder, decoder, classifier)

vae.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist_train*(1-validation_split)/batch_size), alpha=ratio_to_stop)))

early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stop_epochs, restore_best_weights=True)


# Allenamento del modello
history = vae.fit(train_dataset, epochs=n_epochs, validation_data=val_dataset, batch_size=batch_size, verbose=2, callbacks=[early_stop])



# Salva lo storico dell'addestramento in formato pickle
hist = pd.DataFrame(history.history)  # Converti history.history (dati storici dell'addestramento) in un DataFrame di pandas
hist['epoch'] = history.epoch  # Aggiungi una colonna per le epoche. history.epoch è una lista che contiene i numeri delle epoche per cui sono stati registrati i dati.

# Salva il DataFrame
try:
    hist.to_pickle(os.path.join(path_save, 'hist_VAE_1D.pkl'))   #Salva il DataFrame hist in un file con formato pickle.
    print(f"Storico salvato in {os.path.join(path_save, 'hist_VAE_1D.pkl')}")
except Exception as e:
    print(f"Errore durante il salvataggio dello storico: {e}")

# Salva il modello
try:
    vae.save(os.path.join(path_save, 'model_VAE_1D.keras'))   # Salva il modello vae addestrato in formato Keras
    print(f"Modello salvato in {os.path.join(path_save, 'model_VAE_1D.keras')}")
except Exception as e:
    print(f"Errore durante il salvataggio del modello: {e}")

# Salva i pesi
vae.save_weights('./models/VAE_1D.weights.h5')




"""
## Output
"""

# Crea la cartella se non esiste
output_dir = "output_VAE_1D"
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Plot combinato per la training loss e la validation loss
plt.figure(figsize=(15, 5))  # Dimensioni del plot
plt.plot(history.history["loss"], label="Training Loss", color='blue')
plt.plot(history.history["val_loss"], label="Validation Loss", color='orange')
plt.title("Training and Validation Loss")
plt.ylabel("Loss")
plt.xlabel("Epoch")
plt.legend(loc="upper right")
plt.grid(True)
plt.savefig(os.path.join(output_dir, "losses.png"))
plt.show()
plt.close()


def plot_label_clusters(vae, data, labels):
    # display a 2D plot of the digit classes in the latent space
    z_mean, _, _ = vae.encoder.predict(data, verbose=0)

    print(f"Forma di z_mean: {z_mean.shape}")
    print(f"Primi elementi di z_mean:\n{z_mean[0:4,:]}")

    plt.figure(figsize=(12, 10))
    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)
    plt.colorbar()
    plt.xlabel("z_mean[0]")
    plt.ylabel("z_mean[1]")
    # Imposta il titolo della figura
    plt.suptitle(f'Grouped by damage class', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_2d.png"))
    plt.close()


def plot_label_clusters_3d(vae, data, labels):
    # display a 3D plot of the digit classes in the latent space
    z_mean, _, _ = vae.encoder.predict(data, verbose=0)

    print(f"Forma di z_mean: {z_mean.shape}")
    print(f"Primi elementi di z_mean:\n{z_mean[0:4,:]}")

    if z_mean.shape[1] < 3:
        print("Attenzione: z_mean ha meno di 3 dimensioni. Potrebbe non essere possibile creare un grafico 3D.")
        return

    # Crea una figura 3D
    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')

    # Plotta i dati 3D, con i colori basati sulle etichette
    scatter = ax.scatter(z_mean[:, 0], z_mean[:, 1], z_mean[:, 2], c=labels, cmap='viridis')

    # Aggiungi una barra colore
    color_bar = fig.colorbar(scatter, ax=ax)
    color_bar.set_label('Classi')

    # Etichette degli assi
    ax.set_xlabel("z_mean[0]")
    ax.set_ylabel("z_mean[1]")
    ax.set_zlabel("z_mean[2]")

    # Imposta il titolo della figura
    plt.suptitle(f'Grouped by damage class in 3D latent space', fontsize=16)

    # Salva il grafico
    plt.savefig(os.path.join(output_dir, "label_clusters_3d.png"))

    # Mostra il grafico
    plt.show()


# Esempio di chiamata alla funzione
# plot_label_clusters(vae, observations_normalized , damage_class_labels)
plot_label_clusters_3d(vae, observations_normalized , damage_class_labels)