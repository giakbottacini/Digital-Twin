"""
Title: VAE for the MCMC structure
"""

import os

os.environ["KERAS_BACKEND"] = "tensorflow"

import numpy as np
import pymc as pm
import tensorflow as tf
import keras
from keras import ops
from keras import layers
from keras import regularizers
from keras import losses
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as st

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_absolute_error, r2_score
import seaborn as sns
from sklearn.manifold import MDS, TSNE
from sklearn.decomposition import PCA




# Specify the example you are dealing with
esempio = 'L_FRAME_DT'
# Training and Testing data
ID              = '7_1'
save_ID         = 'Classifier_total_7_1/'
path            = "../" + esempio + '/Dati/'
path_data_train   = path + 'istantrain_' + ID
path_data_test   = path + 'istantest_' + ID
# Saving model
path_save       = "models/"
# Prediction model
restore_ID= 'Classifier_total_7_1/'
path_restore = path + restore_ID

# Which dof monitored
which_channels = [1,2,3,4,5,6,7,8]

n_channels = 8
seq_len = 200
# addedd_SNR = 100
# Specify if you are using accelerations =1 or displacements =0
accelerations = 0







def RMS(signal):
    return np.sqrt(np.mean(signal**2))


def read_data(path_data, addedd_SNR):    
    label_path_class = path_data + '/Damage_class.csv'                                
    labels_class     = np.genfromtxt(label_path_class)
    labels_class     = labels_class.astype('int')
    label_path_level = path_data + '/Damage_level.csv'                                
    labels_level     = np.genfromtxt(label_path_level)

    # Filtra gli indici con damage_class diversa da 0
    valid_indices = np.where(labels_class != 0)[0]
    
    # Aggiorna il numero di istanze valide
    N_ist = len(valid_indices)

    if accelerations == 1:
        path_rec  = path_data + '/U2_concat_'
    elif accelerations == 0:
        path_rec  = path_data + '/U_concat_'

    if path_data == path_data_train:
        signals_means = np.zeros((n_channels))
        signals_stds = np.zeros((n_channels))
    else:
        signals_means = np.load(path_restore+'/Corrupted_signals_means.npy')
        signals_stds = np.load(path_restore+'/Corrupted_signals_stds.npy')

    # Creiamo la struttura per i segnali
    X = np.zeros((N_ist, seq_len, n_channels))
    # Creiamo i segnali corrotti
    X_noise = np.zeros((N_ist, seq_len, n_channels))
    
    for i1 in range(n_channels):
        path_data_var  = path_rec + str(which_channels[i1]) + '.csv'
        X_singledof = pd.read_csv(path_data_var, header=None).to_numpy()[:,0]
        for i2, idx in enumerate(valid_indices):
            # RESHAPE THE SIGNALS
            X[i2, :, i1] = X_singledof[1 + idx*(1 + seq_len) : (idx + 1)*(1 + seq_len)]
            # # CORRUPT THE SIGNALS
            rms_signal = RMS(X[i2,:,i1])
            dev_std    = rms_signal / np.sqrt(addedd_SNR)
            sample = st.norm(0, dev_std)
            X_noise[i2, :, i1] = X[i2, :, i1] + sample.rvs(size=seq_len)
        if path_data == path_data_train:
            # COMPUTE STATISTICS FOR EACH CHANNEL
            signals_means[i1] = np.mean(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            signals_stds[i1] = np.std(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
   
    # NORMALIZZA I SEGNALI    
    for i1 in range(n_channels):
        X_noise[:,:,i1] = (X_noise[:,:,i1] - signals_means[i1]) / signals_stds[i1]
        
    # Creazione dei vettori di label di 7 elementi
    labels_vector = np.zeros((N_ist, 7))  # Vettore di etichette a 7 classi
    
    for i, idx in enumerate(valid_indices):
        # Inserisci il damage_level nella posizione corretta in base alla classe di danno
        damage_class = labels_class[idx] - 1  # Mappiamo la classe 1 su 0, 2 su 1, ecc.
        damage_level = labels_level[idx]
        labels_vector[i][damage_class] = damage_level - 0.25

    return X_noise, labels_vector, N_ist
















"""
## Create a sampling layer
"""

class Sampling(layers.Layer):
    """Uses (z_mean, z_log_var) to sample z, the vector encoding a digit."""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.seed_generator = keras.random.SeedGenerator(1337)

    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = ops.shape(z_mean)[0]
        dim = ops.shape(z_mean)[1]
        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)
        return z_mean + ops.exp(0.5 * z_log_var) * epsilon



"""
## Using Matteo's architecture
"""

n_class = 7
latent_dim = 4

# Hyperparameters
validation_split = 0.20
batch_size = 32
n_epochs = 250
early_stop_epochs=25
initial_lr = 1e-3
decay_length = 0.8
ratio_to_stop = 0.05

filter_1      = 32;   filter_2      = 64;   filter_3      = 32
kernel_size_1 = 25;   kernel_size_2 =  13;   kernel_size_3 = 7
neurons_4 = 64
neurons_5 = 16
attivaz_conv = 'tanh'
attivaz_mlp = 'tanh'
k_reg = 1e-3
b_reg = 1e-3
rate_drop = 0.05

"""
## Build the encoder 
"""

encoder_inputs  = layers.Input(shape=(seq_len, n_channels), name='Convolutional_inputs')
x = layers.Conv1D(filters=filter_1, kernel_size=kernel_size_1, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_1')(encoder_inputs)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)   #Gli strati Dropout vengono utilizzati per regolarizzare il modello durante l'addestramento, disattivando casualmente una frazione di neuroni. Questo aiuta a prevenire l'overfitting.

x = layers.Conv1D(filters=filter_2, kernel_size=kernel_size_2, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_2')(x)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1D(filters=filter_3, kernel_size=kernel_size_3, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=attivaz_conv, name='Conv_3')(x)
x = layers.MaxPooling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Flatten()(x)

x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(x)
x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)

z_mean = layers.Dense(latent_dim, activation=None, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='z_mean')(x)
z_log_var = layers.Dense(latent_dim, activation=None, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='z_log_var')(x)
z = Sampling()([z_mean, z_log_var])

# Definisci il modello
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
encoder.summary()

"""
## Build the decoder 
"""

latent_inputs_decoder = layers.Input(shape=(latent_dim,), name='Latent_inputs')

x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1_decoder')(latent_inputs_decoder)
x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2_decoder')(x)
x = layers.Dense(units=filter_3 * (seq_len // 8), activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3_decoder')(x)
x = layers.Reshape((seq_len // 8, filter_3))(x)

# Applica strati Conv1DTranspose (o Conv1D per upsampling)
x = layers.Conv1DTranspose(filters=filter_3, kernel_size=kernel_size_3, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_1')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1DTranspose(filters=filter_2, kernel_size=kernel_size_2, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_2')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

x = layers.Conv1DTranspose(filters=filter_1, kernel_size=kernel_size_1, activation=attivaz_conv, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='ConvT_3')(x)
x = layers.UpSampling1D()(x)
x = layers.Dropout(rate=rate_drop)(x)

# Ultimo livello per tornare alla forma originale
decoder_outputs = layers.Conv1D(filters=n_channels, kernel_size=kernel_size_1, activation=None, padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Conv_1_decoder')(x)

# Definisci il modello
decoder = keras.Model(latent_inputs_decoder, decoder_outputs, name='decoder')
decoder.summary()




"""
## Build the Dense layer
"""

latent_inputs_classifier = layers.Input(shape=(latent_dim,), name='Latent_inputs')

x = layers.Dense(units=64, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(latent_inputs_classifier)
x = layers.Dense(units=32, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)
# Layer di output del classificatore con attivazione lineare
Dense_output = layers.Dense(n_class, activation='linear', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3_linear')(x)


# Definisci il modello
classifier = keras.Model(latent_inputs_classifier, Dense_output, name='classifier')
classifier.summary()





"""
## Define the VAE class
"""

class VAE(keras.Model):
    def __init__(self, encoder, decoder, classifier,**kwargs):
        super().__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.classifier = classifier
        self.total_loss_tracker = keras.metrics.Mean(name="total_loss")
        self.reconstruction_loss_tracker = keras.metrics.Mean(name="reconstruction_loss")
        self.kl_loss_tracker = keras.metrics.Mean(name="kl_loss")
        self.classification_loss_tracker = keras.metrics.Mean(name="classification_loss")

    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
        ]

    def train_step(self, data):

        observations, damage_class_labels = data


        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(observations)

            reconstruction = self.decoder(z)

            # Predizione per la classificazione
            classification_preds = self.classifier(z)

            reconstruction_loss = ops.mean(
                ops.sum(
                    # keras.losses.binary_crossentropy(observations, reconstruction), #La funzione keras.losses.binary_crossentropy(data, reconstruction) restituisce un tensore bidimensionale di forma (batch_size, time_steps). 
                                                                                      #Questo avviene perché binary_crossentropy calcola la perdita per ogni time step, non per ogni canale.
                    keras.losses.mean_squared_error(observations, reconstruction),  # Calcola la perdita MSE tra dati originali e ricostruiti
                    axis=1,   
                )
            )
            
            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))
            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))

            # Perdita di classificazione (categorical crossentropy)
            classification_loss = keras.losses.mean_squared_error(damage_class_labels, classification_preds)
            classification_loss = tf.reduce_mean(classification_loss)

            beta = 1.0
            gamma = 3000.0
            total_loss = reconstruction_loss + beta * kl_loss + gamma * classification_loss

        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))

        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        self.classification_loss_tracker.update_state(classification_loss)
        return {
            "loss": self.total_loss_tracker.result(),
            "reconstruction_loss": self.reconstruction_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
            "classification_loss": self.classification_loss_tracker.result(),
        }
    
    
    def test_step(self, data):
        observations, damage_class_labels = data
        z_mean, z_log_var, z = self.encoder(observations)
        reconstruction = self.decoder(z)
        classification_preds = self.classifier(z)

        # Calcolo della perdita per il test
        reconstruction_loss = ops.mean(
            ops.sum(
                # keras.losses.binary_crossentropy(data, reconstruction), #La funzione keras.losses.binary_crossentropy(data, reconstruction) restituisce un tensore bidimensionale di forma (batch_size, time_steps). 
                                                                          #Questo avviene perché binary_crossentropy calcola la perdita per ogni time step, non per ogni canale.
                keras.losses.mean_squared_error(observations, reconstruction),  # Calcola la perdita MSE tra dati originali e ricostruiti
                axis=1,   
                )
            )
        
        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)
        kl_loss = tf.reduce_mean(kl_loss)

        classification_loss = keras.losses.mean_squared_error(damage_class_labels, classification_preds)
        classification_loss = tf.reduce_mean(classification_loss)

        beta = 1.0
        gamma = 3000.0
        total_loss = reconstruction_loss + beta * kl_loss + gamma * classification_loss

        return {
            "loss": total_loss,
            "reconstruction_loss": reconstruction_loss,
            "kl_loss": kl_loss,
            "classification_loss": classification_loss,
        }
    
    
    def call(self, inputs):
        # Passaggio attraverso l'encoder
        z_mean, z_log_var, z = self.encoder(inputs)
        
        # Decodifica del campione z
        reconstructed = self.decoder(z)

        # Decodifica del campione z
        classified = self.classifier(z)
        
        return reconstructed, classified





"""
## Funzioni utili
"""


def plot_label_clusters(vae, data, labels):
    # display a 2D plot of the digit classes in the latent space
    z_mean, _, _ = vae.encoder.predict(data, verbose=0)

    print(f"Forma di z_mean: {z_mean.shape}")
    print(f"Primi elementi di z_mean:\n{z_mean[0:4,:]}")

    plt.figure(figsize=(12, 10))
    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)
    plt.colorbar()
    plt.xlabel("z_mean[0]")
    plt.ylabel("z_mean[1]")
    # Imposta il titolo della figura
    plt.suptitle(f'Grouped by damage class', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_2d.png"))
    plt.close()




def plot_label_clusters_3d(vae, data, labels):
    # display a 3D plot of the digit classes in the latent space
    z_mean, _, _ = vae.encoder.predict(data, verbose=0)

    print(f"Forma di z_mean: {z_mean.shape}")
    print(f"Primi elementi di z_mean:\n{z_mean[0:4,:]}")

    if z_mean.shape[1] < 3:
        print("Attenzione: z_mean ha meno di 3 dimensioni. Potrebbe non essere possibile creare un grafico 3D.")
        return
    

    # Plot using nothing
    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')
    scatter = ax.scatter(z_mean[:, 0], z_mean[:, 1], z_mean[:, 2], c=labels, cmap='viridis')
    color_bar = fig.colorbar(scatter, ax=ax)
    color_bar.set_label('Classi')
    ax.set_xlabel("z_mean[0]")
    ax.set_ylabel("z_mean[1]")
    ax.set_zlabel("z_mean[2]")
    plt.suptitle(f'Grouped by damage class in 3D latent space', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_3d.png"))
    plt.show()


    # # Plot using MDS
    # mds = MDS(n_components=3)
    # z_mds = mds.fit_transform(z_mean)

    # fig = plt.figure(figsize=(12, 10))
    # ax = fig.add_subplot(111, projection='3d')
    # scatter = ax.scatter(z_mds[:, 0], z_mds[:, 1], z_mds[:, 2], c=labels, cmap='viridis')
    # color_bar = fig.colorbar(scatter, ax=ax)
    # color_bar.set_label('Classi')
    # ax.set_xlabel("MDS[0]")
    # ax.set_ylabel("MDS[1]")
    # ax.set_zlabel("MDS[2]")
    # plt.suptitle(f'Grouped by damage class in 3D latent space using MDS', fontsize=16)
    # plt.savefig(os.path.join(output_dir, "label_clusters_mds_3d.png"))
    # plt.show()

    # # Plot using TSNE  (in teoria serve più che altro se hai input categoriale)
    # tsne = TSNE(n_components=3)
    # z_tsne = tsne.fit_transform(z_mean)

    # fig = plt.figure(figsize=(12, 10))
    # ax = fig.add_subplot(111, projection='3d')
    # scatter = ax.scatter(z_tsne[:, 0], z_tsne[:, 1], z_tsne[:, 2], c=labels, cmap='viridis')
    # color_bar = fig.colorbar(scatter, ax=ax)
    # color_bar.set_label('Classi')
    # ax.set_xlabel("TSNE[0]")
    # ax.set_ylabel("TSNE[1]")
    # ax.set_zlabel("TSNE[2]")
    # plt.suptitle(f'Grouped by damage class in 3D latent space using TSNE', fontsize=16)
    # plt.savefig(os.path.join(output_dir, "label_clusters_tsne_3d.png"))
    # plt.show()

    # Plot using PCA
    pca = PCA(n_components=3)
    z_pca = pca.fit_transform(z_mean)

    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')
    scatter = ax.scatter(z_pca[:, 0], z_pca[:, 1], z_pca[:, 2], c=labels, cmap='viridis')
    color_bar = fig.colorbar(scatter, ax=ax)
    color_bar.set_label('Classi')
    ax.set_xlabel("PCA[0]")
    ax.set_ylabel("PCA[1]")
    ax.set_zlabel("PCA[2]")
    plt.suptitle(f'Grouped by damage class in 3D latent space using PCA', fontsize=16)
    plt.savefig(os.path.join(output_dir, "label_clusters_pca_3d.png"))
    plt.show()



def evaluate_classification(y_true, y_pred_class):
    """
    Funzione per valutare le performance di classificazione.
    
    Args:
        y_true (ndarray): Array delle classi reali (ground truth).
        y_pred_class (ndarray): Array delle classi predette dal modello (previsioni).
    
    Returns:
        metrics (dict): Dizionario con accuracy, precision, recall e F1-score.
    """
    # Calcola accuracy
    accuracy = accuracy_score(y_true, y_pred_class)
    
    # Calcola precision, recall, F1-score (macro per avere una media su tutte le classi)
    precision = precision_score(y_true, y_pred_class, average='macro')
    recall = recall_score(y_true, y_pred_class, average='macro')
    f1 = f1_score(y_true, y_pred_class, average='macro')
    
    # Calcola e visualizza confusion matrix
    cm = confusion_matrix(y_true, y_pred_class)
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.xlabel('Predicted Class')
    plt.ylabel('True Class')
    plt.title('Confusion Matrix')
    plt.show()
    
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1
    }
    
    return metrics

def evaluate_regression(y_true, y_pred_damage_level):
    """
    Funzione per valutare le performance di regressione (livello di danno).
    """

    # Mean Absolute Error
    mae = mean_absolute_error(y_true, y_pred_damage_level)
    
    # Mean Squared Error
    mse = mean_squared_error(y_true, y_pred_damage_level)
    
    # R² Score
    r2 = r2_score(y_true, y_pred_damage_level)
    
    metrics = {
        'mean_absolute_error': mae,
        'mean_squared_error': mse,
        'r2_score': r2
    }
    
    return metrics


def extract_class_and_damage_level(labels):

    classes = np.argmax(labels, axis=1)
    damage_levels = np.max(labels, axis=1)

    return classes, damage_levels


def evaluate_model_performance(true_labels, predicted_labels):
    """
    Valuta le performance del modello confrontando i true_labels con i predicted_labels.
    
    Args:
        true_labels (ndarray): Etichette vere (vettori di 8 elementi).
        predicted_labels (ndarray): Etichette predette dal modello (vettori di 8 elementi).
    
    Returns:
        performance_metrics (dict): Dizionario con le metriche di performance (accuratezza e MAE).
    """
    # Estrai classi e livelli di danno dalle etichette vere e predette
    true_classes, true_damage_levels = extract_class_and_damage_level(true_labels)
    predicted_classes, predicted_damage_levels = extract_class_and_damage_level(predicted_labels)
    
    # Calcola l'accuratezza della classificazione
    classification_accuracy = accuracy_score(true_classes, predicted_classes)
    
    # Calcola l'errore medio assoluto (MAE) per la regressione del livello di danno
    damage_mae = mean_absolute_error(true_damage_levels, predicted_damage_levels)
    
    # Stampa i risultati
    print(f"Classification Accuracy: {classification_accuracy:.4f}")
    print(f"Damage Level Mean Absolute Error (MAE): {damage_mae:.4f}")
    
    # Restituisci un dizionario con le metriche di performance
    performance_metrics = {
        "classification_accuracy": classification_accuracy,
        "damage_mae": damage_mae
    }
    
    return performance_metrics







train_or_predict = 0   # 1: training, 0: predict                                       


if train_or_predict:

    """
    ## Model training
    """

    X_train, labels, N_ist = read_data(path_data_train, 100)

    print(f"Forma di X_train: {X_train.shape}")

    print(f"Forma di labels: {labels.shape}")

    print("Prime 2 righe di labels:")
    print(labels[:2])


    # Separare i dati in training e validation set
    train_observations, val_observations, train_labels, val_labels = train_test_split(X_train, labels, test_size=validation_split, random_state=42)

    # Creare dataset TensorFlow per il training
    train_dataset = tf.data.Dataset.from_tensor_slices((train_observations, train_labels))
    train_dataset = train_dataset.batch(batch_size)

    # Creare dataset TensorFlow per la validazione
    val_dataset = tf.data.Dataset.from_tensor_slices((val_observations, val_labels))
    val_dataset = val_dataset.batch(batch_size)

    vae = VAE(encoder, decoder, classifier)

    vae.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist*(1-validation_split)/batch_size), alpha=ratio_to_stop)))

    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stop_epochs, restore_best_weights=True)


    # Allenamento del modello
    history = vae.fit(train_dataset, epochs=n_epochs, validation_data=val_dataset, batch_size=batch_size, verbose=2, callbacks=[early_stop])


    # Salva lo storico dell'addestramento in formato pickle
    hist = pd.DataFrame(history.history)  # Converti history.history (dati storici dell'addestramento) in un DataFrame di pandas
    hist['epoch'] = history.epoch  # Aggiungi una colonna per le epoche. history.epoch è una lista che contiene i numeri delle epoche per cui sono stati registrati i dati.

    # Salva il DataFrame
    try:
        hist.to_pickle(os.path.join(path_save, 'hist_VAE_for_MCMC.pkl'))   #Salva il DataFrame hist in un file con formato pickle.
        print(f"Storico salvato in {os.path.join(path_save, 'hist_VAE_for_MCMC.pkl')}")
    except Exception as e:
        print(f"Errore durante il salvataggio dello storico: {e}")

    # Salva il modello
    try:
        vae.save(os.path.join(path_save, 'model_VAE_for_MCMC.keras'))   # Salva il modello vae addestrato in formato Keras
        print(f"Modello salvato in {os.path.join(path_save, 'model_VAE_for_MCMC.keras')}")
    except Exception as e:
        print(f"Errore durante il salvataggio del modello: {e}")

    # Salva i pesi
    vae.save_weights('./models/VAE_for_MCMC.weights.h5')


    """
    ## Output
    """

    # Crea la cartella se non esiste
    output_dir = "output_VAE_for_MCMC"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Plot combinato per la training loss e la validation loss
    plt.figure(figsize=(15, 5))  # Dimensioni del plot
    plt.plot(history.history["loss"], label="Training Loss", color='blue')
    plt.plot(history.history["val_loss"], label="Validation Loss", color='orange')
    plt.title("Training and Validation Loss")
    plt.ylabel("Loss")
    plt.xlabel("Epoch")
    plt.legend(loc="upper right")
    plt.grid(True)
    plt.savefig(os.path.join(output_dir, "losses.png"))
    plt.show()
    plt.close()

    damage_class_labels = np.argmax(labels, axis=1)
    # plot_label_clusters(vae, observations_normalized , damage_class_labels)
    plot_label_clusters_3d(vae, X_train , damage_class_labels)


else:

    """
    ## Predict
    """

    # Caricamento dei dati di test
    X_test, labels_test, N_ist_test = read_data(path_data_test, 100)

    print(f"Forma di X_test: {X_test.shape}")

    # Creare dataset TensorFlow per il testing
    # test_dataset = tf.data.Dataset.from_tensor_slices((X_test, labels_test))
    # test_dataset = test_dataset.batch(batch_size)


    # Creazione dell'istanza VAE
    vae = VAE(encoder, decoder, classifier)
    vae.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist_test*(1-validation_split)/batch_size), alpha=ratio_to_stop)))

    # Caricamento dei pesi salvati
    vae.load_weights('./models/VAE_for_MCMC.weights.h5')    
    



    import time

    # Selezione casuale di 3 indici da Z_test
    random_indices = np.random.choice(X_test.shape[0], size=2, replace=False)

    # Inizio del timer per i 3 campioni
    start_time = time.time()

    # Predizione per i 3 campioni selezionati
    X_test_reconstructed, X_test_labels = vae.predict(X_test[random_indices])

    # Fine del timer e calcolo del tempo
    end_time = time.time()
    random_time = end_time - start_time
    print(f"Tempo di esecuzione per 3 campioni casuali: {random_time} secondi")


    # Selezione casuale di 3 indici da Z_test
    random_indices = np.random.choice(X_test.shape[0], size=2, replace=False)

    # Inizio del timer per i 3 campioni
    start_time = time.time()

    # Predizione per i 3 campioni selezionati
    X_test_reconstructed, X_test_labels = vae.predict(X_test[random_indices])

    # Fine del timer e calcolo del tempo
    end_time = time.time()
    random_time = end_time - start_time
    print(f"Tempo di esecuzione per 3 campioni casuali: {random_time} secondi")

    




    # Ricostruzione dei dati di test
    X_test_reconstructed, X_test_labels = vae.predict(X_test)

    # Caricamento della cronologia dell'addestramento
    hist = pd.read_pickle(path_save + 'hist_VAE_for_MCMC.pkl')



    # Ottieni le classi previste
    predicted_classes = np.argmax(X_test_labels, axis=1)


    output_dir = "output_VAE_for_MCMC"


    
    """
    ## Analisi della classificazione
    """

    # Ottieni le classi vere
    true_classes = np.argmax(labels_test, axis=1)

    # Calcola metriche di classificazione
    accuracy = accuracy_score(true_classes, predicted_classes)
    precision = precision_score(true_classes, predicted_classes, average='weighted')
    recall = recall_score(true_classes, predicted_classes, average='weighted')
    f1 = f1_score(true_classes, predicted_classes, average='weighted')

    # Calcola la matrice di confusione
    conf_matrix = confusion_matrix(true_classes, predicted_classes)

    # Crea una figura con due sotto-figure
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 14))

    # Plot della matrice di confusione
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax1)
    ax1.set_title('Confusion Matrix')
    ax1.set_xlabel('Predicted Label')
    ax1.set_ylabel('True Label')

    # Aggiungi le metriche di classificazione come testo nella seconda sotto-figura
    metrics_text = (
        f"Accuracy: {accuracy:.4f}\n"
        f"Precision: {precision:.4f}\n"
        f"Recall: {recall:.4f}\n"
        f"F1-Score: {f1:.4f}"
    )
    ax2.text(0.5, 0.5, metrics_text, fontsize=12, ha='center', va='center')
    ax2.set_axis_off()  # Nascondi gli assi

    # Salva il grafico
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "Confusion_Matrix_VAE.png"))

    # Mostra il grafico
    plt.show()


    """
    ## Analisi della classificazione e regressione
    """

    performance_metrics = evaluate_model_performance(labels_test, X_test_labels)
    print(performance_metrics)



    """
    ## Creazione latent dataset di train e test
    """

    # X_train, labels_train, N_ist_train = read_data(path_data_train, 100)
    # X_test, labels_test, N_ist_test = read_data(path_data_test, 100)

    # # Usa l'encoder per ottenere i vettori latenti
    # _, _, z_train = vae.encoder.predict(X_train)
    # _, _, z_test = vae.encoder.predict(X_test)
    
    # # Convertili in un dataframe per facilità di salvataggio
    # latent_space_train_df = pd.DataFrame(z_train)
    # latent_space_test_df = pd.DataFrame(z_test)
    
    # # Crea il percorso completo del file
    # full_path_train = os.path.join(output_dir, "z_train.csv")
    # full_path_test = os.path.join(output_dir, "z_test.csv")
    
    # # Salva il dataframe in formato CSV
    # latent_space_train_df.to_csv(full_path_train, index=False)
    # latent_space_test_df.to_csv(full_path_test, index=False)
    


    """
    ## Creazione latent dataset di train e test 2
    """

    X_train, labels_train, N_ist_train = read_data(path_data_train, 100)
    X_test, labels_test, N_ist_test = read_data(path_data_test, 100)

    # Usa l'encoder per ottenere i vettori latenti (media e varianza)
    z_mean_train, z_log_var_train, _ = vae.encoder.predict(X_train)
    z_mean_test, z_log_var_test, _ = vae.encoder.predict(X_test)

    # Concatena media e varianza lungo l'asse delle colonne
    # Questo creerà un array con la media seguita dalla varianza per ogni dimensione latente
    z_train_combined = np.concatenate([z_mean_train, z_log_var_train], axis=1)
    z_test_combined = np.concatenate([z_mean_test, z_log_var_test], axis=1)
    
    # Convertili in un dataframe per facilità di salvataggio
    # Per chiarezza, nominiamo le colonne come "mean_0", "mean_1", ..., "var_0", "var_1", ...
    columns_train = [f"mean_{i}" for i in range(z_mean_train.shape[1])] + [f"var_{i}" for i in range(z_log_var_train.shape[1])]
    latent_space_train_df = pd.DataFrame(z_train_combined, columns=columns_train)

    columns_test = [f"mean_{i}" for i in range(z_mean_test.shape[1])] + [f"var_{i}" for i in range(z_log_var_test.shape[1])]
    latent_space_test_df = pd.DataFrame(z_test_combined, columns=columns_test)

    # Crea il percorso completo del file
    full_path_train = os.path.join(output_dir, "z_train2.csv")
    full_path_test = os.path.join(output_dir, "z_test2.csv")

    # Salva il dataframe in formato CSV
    latent_space_train_df.to_csv(full_path_train, index=False)
    latent_space_test_df.to_csv(full_path_test, index=False)