"""
Title: VAE for the MCMC structure
"""

import os

os.environ["KERAS_BACKEND"] = "tensorflow"

import numpy as np
import pymc as pm
import tensorflow as tf
import keras
from keras import ops
from keras import layers
from keras import regularizers
from keras import losses
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as st

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_absolute_error, r2_score
import seaborn as sns
from sklearn.manifold import MDS, TSNE
from sklearn.decomposition import PCA




# Specify the example you are dealing with
esempio = 'TRAIN_FRAME_DT'
# Training and Testing data
ID              = '2_1'
save_ID         = '/Classifier_total_2_1/'
path            = "../" + esempio 
path_data_train   = path + '/istantrain_' + ID
path_data_test   = path + '/istantest_' + ID
# Saving model
path_save       = "models/"
# Prediction model
restore_ID= '/Classifier_total_2_1/'
path_restore = path + restore_ID

# Which dof monitored
which_channels = [1,2,3,4,5,6,7,8,9,10]

n_channels = 10
seq_len = 600
# Specify if you are using accelerations =1 or displacements =0
accelerations = 0


n_class = 6


def RMS(signal):
    return np.sqrt(np.mean(signal**2))


def read_data_0(path_data, addedd_SNR):    
    label_path_class = path_data + '/Damage_class.csv'                                
    labels_class     = np.genfromtxt(label_path_class)
    labels_class     = labels_class.astype('int')
    label_path_level = path_data + '/Damage_level.csv'                                
    labels_level     = np.genfromtxt(label_path_level)
    
    valid_indices = np.arange(len(labels_class))

    # Total number of instances
    N_ist = len(labels_class)
    
    if accelerations == 1:
        path_rec  = path_data + '/U2_concat_'
    elif accelerations == 0:
        path_rec  = path_data + '/U_concat_'

    if path_data == path_data_train:
        signals_means = np.zeros((n_channels))
        signals_stds = np.zeros((n_channels))
    else:
        signals_means = np.load(path_restore+'/Corrupted_signals_means.npy')
        signals_stds = np.load(path_restore+'/Corrupted_signals_stds.npy')

    # Creiamo la struttura per i segnali
    X = np.zeros((N_ist, seq_len, n_channels))
    # Creiamo i segnali corrotti
    X_noise = np.zeros((N_ist, seq_len, n_channels))
    
    for i1 in range(n_channels):
        path_data_var  = path_rec + str(which_channels[i1]) + '.csv'
        X_singledof = pd.read_csv(path_data_var, header=None).to_numpy()[:,0]

        for i2, idx in enumerate(valid_indices):
            # RESHAPE THE SIGNALS
            X[i2, :, i1] = X_singledof[1 + idx*(1 + seq_len) : (idx + 1)*(1 + seq_len)]
            # CORRUPT THE SIGNALS
            rms_signal = RMS(X[i2,:,i1])
            dev_std    = rms_signal / np.sqrt(addedd_SNR)
            sample = st.norm(0, dev_std)
            X_noise[i2, :, i1] = X[i2, :, i1] + sample.rvs(size=seq_len)
        if path_data == path_data_train:
            # COMPUTE STATISTICS FOR EACH CHANNEL
            signals_means[i1] = np.mean(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            signals_stds[i1] = np.std(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
   
    # NORMALIZZA I SEGNALI    
    for i1 in range(n_channels):
        X_noise[:,:,i1] = (X_noise[:,:,i1] - signals_means[i1]) / signals_stds[i1]
        
    # Creazione dei vettori di label di n_class elementi
    labels_vector = np.zeros((N_ist, n_class))  # Vettore di etichette a 7 classi
    
    for i, val in enumerate(labels_class):
        damage_class = val - 1  # Mappiamo la classe 1 su 0, 2 su 1, ecc.
        damage_level = labels_level[i]
        
        if damage_class == -1:  # Se damage_class Ã¨ 0 (mappato a -1)
            labels_vector[i] = np.zeros(n_class)  # Imposta il vettore con tutti gli zeri
        else:
            labels_vector[i][damage_class] = damage_level - 0.25  # Inserisci il damage_level nella posizione corretta
    
    return X, labels_vector, N_ist



def read_data(path_data, addedd_SNR):    
    label_path_class = path_data + '/Damage_class.csv'                                
    labels_class     = np.genfromtxt(label_path_class)
    labels_class     = labels_class.astype('int')
    label_path_level = path_data + '/Damage_level.csv'                                
    labels_level     = np.genfromtxt(label_path_level)

    # Filtra gli indici con damage_class diversa da 0
    valid_indices = np.where(labels_class != 0)[0]
    
    # Aggiorna il numero di istanze valide
    N_ist = len(valid_indices)

    if accelerations == 1:
        path_rec  = path_data + '/U2_concat_'
    elif accelerations == 0:
        path_rec  = path_data + '/U_concat_'

    if path_data == path_data_train:
        signals_means = np.zeros((n_channels))
        signals_stds = np.zeros((n_channels))
    else:
        signals_means = np.load(path_restore+'/Corrupted_signals_means.npy')
        signals_stds = np.load(path_restore+'/Corrupted_signals_stds.npy')

    # Creiamo la struttura per i segnali
    X = np.zeros((N_ist, seq_len, n_channels))
    # Creiamo i segnali corrotti
    X_noise = np.zeros((N_ist, seq_len, n_channels))
    
    for i1 in range(n_channels):
        path_data_var  = path_rec + str(which_channels[i1]) + '.csv'
        X_singledof = pd.read_csv(path_data_var, header=None).to_numpy()[:,0]
        for i2, idx in enumerate(valid_indices):
            # RESHAPE THE SIGNALS
            X[i2, :, i1] = X_singledof[1 + idx*(1 + seq_len) : (idx + 1)*(1 + seq_len)]
            # # CORRUPT THE SIGNALS
            rms_signal = RMS(X[i2,:,i1])
            dev_std    = rms_signal / np.sqrt(addedd_SNR)
            sample = st.norm(0, dev_std)
            X_noise[i2, :, i1] = X[i2, :, i1] + sample.rvs(size=seq_len)
        if path_data == path_data_train:
            # COMPUTE STATISTICS FOR EACH CHANNEL
            signals_means[i1] = np.mean(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
            signals_stds[i1] = np.std(np.reshape(X_noise[:,:,i1], (N_ist*seq_len)))
   
    # NORMALIZZA I SEGNALI    
    for i1 in range(n_channels):
        X_noise[:,:,i1] = (X_noise[:,:,i1] - signals_means[i1]) / signals_stds[i1]
        
    # Creazione dei vettori di label di n_class elementi
    labels_vector = np.zeros((N_ist, n_class))  # Vettore di etichette a 7 classi
    
    for i, idx in enumerate(valid_indices):
        # Inserisci il damage_level nella posizione corretta in base alla classe di danno
        damage_class = labels_class[idx] - 1  # Mappiamo la classe 1 su 0, 2 su 1, ecc.
        damage_level = labels_level[idx]
        labels_vector[i][damage_class] = damage_level - 0.25

    return X, labels_vector, N_ist


X_train, labels_train, N_ist_train = read_data(path_data_test, 100000)
X_train_0, labels_train_0, N_ist_train_0 = read_data_0(path_data_test, 100000)

print("Shape di X_train:")
print(X_train.shape)

print("Shape di X_train_0:")
print(X_train_0.shape)

# Stampa delle prime righe di labels_train
print("Prime 10 righe di X_train:")
print(X_train[:3])

print("Prime 10 righe di X_train_0:")
print(X_train_0[:3])

print("--------------------------")

print("Shape di labels_train:")
print(labels_train.shape)

print("Shape di labels_train_0:")
print(labels_train_0.shape)

# Stampa delle prime righe di labels_train
print("Prime 10 righe di labels_train:")
print(labels_train[:10])

print("Prime 10 righe di labels_train_0:")
print(labels_train_0[:10])


# damage_class_labels = np.argmax(labels_train_0, axis=1) + 1  # Shift index by 1 to match class labels

# # If a row is all zeros, set damage_class_labels[i] = 0
# damage_class_labels[np.all(labels_train_0 == 0, axis=1)] = 0

# print("Prime 10 righe di damage_class_labels:")
# print(damage_class_labels[:10])

# damage_levels = np.array([
#     labels_train[i, damage_class_labels[i] - 1] if damage_class_labels[i] > 0 else 0
#     for i in range(labels_train.shape[0])
# ])

# print("Prime 10 righe di damage_levels:")
# print(damage_levels[:10])

