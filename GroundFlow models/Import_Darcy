
import os

os.environ["KERAS_BACKEND"] = "tensorflow"

import numpy as np
import pymc as pm
import tensorflow as tf
import keras
from keras import ops
from keras import layers
from keras import regularizers
from keras import losses
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as st

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_absolute_error, r2_score
import seaborn as sns
from sklearn.manifold import MDS, TSNE
from sklearn.decomposition import PCA




# Specify the example you are dealing with
esempio = 'DARCY_FRAME_DT'
# Training and Testing data
path_data_train   = '../DataGenerationDarcy/data/data_train'
path_data_test   = '../DataGenerationDarcy/data/data_test'
# Saving model
path_save       = "models/"
#Position of mean and std. deviation
path_restore  = '../DataGenerationDarcy/data/'

seq_len = 9
# Specify if you are using accelerations =1 or displacements =0
accelerations = 0





def RMS(signal):
    return np.sqrt(np.mean(signal**2))


def read_data(path_data, added_SNR): 

    #Import labels (coeff of KL of the field)
    labels_path = path_data + '/samples_h1_60.csv'
    labels = np.genfromtxt(labels_path, delimiter=',', dtype=float)

    #Import simulation data from sensors
    sensors_path = path_data + '/sensorsdata_h1_60.csv'
    sensors_data = np.genfromtxt(sensors_path, delimiter=',', dtype=float)

    N_ist = len(labels)  

    # Creiamo la struttura per i segnali
    X = sensors_data.copy()  # Prendi direttamente i dati dai sensori
    X_noise = np.zeros_like(X)  # Stessa dimensione di X

    if path_data == path_data_train:

        #Apply noise
        for i in range(N_ist):
            rms_signal = np.sqrt(np.mean(X[i, :] ** 2))  
            dev_std = rms_signal / np.sqrt(added_SNR)  
            noise = st.norm.rvs(0, dev_std, size=X.shape[1])  
            X_noise[i, :] = X[i, :] + noise  

        # Calcola e salva le statistiche per la normalizzazione
        data_mean = np.mean(X_noise, axis=0)
        data_std = np.std(X_noise, axis=0)

        np.save(path_restore + '/data_mean.npy', data_mean)
        np.save(path_restore + '/data_std.npy', data_std)

    else:

        #Apply noise
        for i in range(N_ist):
            rms_signal = np.sqrt(np.mean(X[i, :] ** 2))  
            dev_std = rms_signal / np.sqrt(added_SNR)  
            noise = st.norm.rvs(0, dev_std, size=X.shape[1])  
            X_noise[i, :] = X[i, :] + noise  

        # Load mean and std_dev used to normalize training set
        data_mean = np.load(path_data + '/data_mean.npy')
        data_std = np.load(path_data + '/data_std.npy')

    # Normalizzazione sicura: evitare divisioni per zero
    data_std[data_std == 0] = 1  # Evita divisioni per 0
    X_noise = (X_noise - data_mean) / data_std

    return X_noise, labels, N_ist



def plot_histogram(X_noise, column_index=0, bins=80):
    data = X_noise[:, column_index]  # Estrai la colonna desiderata

    # Calcola media e deviazione standard per verifica
    mean = np.mean(data)
    std_dev = np.std(data)

    plt.figure(figsize=(8, 5))
    plt.hist(data, bins=bins, density=True, alpha=0.6, color='b', edgecolor='black')

    plt.axvline(mean, color='r', linestyle='dashed', linewidth=2, label=f'Media: {mean:.2f}')
    plt.axvline(mean + std_dev, color='g', linestyle='dashed', linewidth=2, label=f'Std: {std_dev:.2f}')
    plt.axvline(mean - std_dev, color='g', linestyle='dashed', linewidth=2)

    plt.title(f"Istogramma della colonna {column_index} di X_noise")
    plt.xlabel("Valori normalizzati")
    plt.ylabel("Frequenza")
    plt.legend()
    plt.grid()
    plt.show()





X_train, labels_train, N_ist_train = read_data(path_data_train, 10000)

print("Shape di X_train:")
print(X_train.shape)

# Stampa delle prime 5 righe di labels_train
print("Prime 5 righe di X_train:")
print(X_train[:5])


print("Shape di labels_train:")
print(labels_train.shape)

# Stampa delle prime 5 righe di labels_train
print("Prime 5 righe di labels_train:")
print(labels_train[:5])


# Carica il file .npy
mean = np.load('../DataGenerationDarcy/data/data_mean.npy')

# Stampa il contenuto
print(mean)

# Controlla la forma dell'array
print("Shape mean:", mean.shape)
print("Tipo di dati:", mean.dtype)


# Carica il file .npy
std = np.load('../DataGenerationDarcy/data/data_std.npy')

# Stampa il contenuto
print(std)

# Controlla la forma dell'array
print("Shape std:", std.shape)
print("Tipo di dati:", std.dtype)


plot_histogram(X_train, column_index=4, bins=50)
