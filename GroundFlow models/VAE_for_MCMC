"""
Title: VAE for the MCMC structure
"""

import os

os.environ["KERAS_BACKEND"] = "tensorflow"

import numpy as np
import pymc as pm
import tensorflow as tf
import keras
from keras import ops
from keras import layers
from keras import regularizers
from keras import losses
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as st

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_absolute_error, r2_score
import seaborn as sns
from sklearn.manifold import MDS, TSNE
from sklearn.decomposition import PCA





# Specify the example you are dealing with
esempio = 'DARCY_FRAME_DT'
# Training and Testing data
path_data_train   = '../DataGenerationDarcy/data/data_train'
path_data_test   = '../DataGenerationDarcy/data/data_test'
# Saving model
path_save       = "models/"
#Position of mean and std. deviation
path_restore  = '../DataGenerationDarcy/data/'

seq_len = 36 #25 
n_params = 4 #6 #9

# lambdas = np.array([3.86, 3.14, 3.14, 2.55, 2.23, 2.23])  #For lam=0.10
# lambdas = np.array([5.93, 4.32, 4.32, 3.15, 2.57, 2.57])  #For lam=0.18
# lambdas = np.array([0.0, 0.0, 0.0, 0.0])   #For 3x3 case
# lambdas = np.array([17.8, 6.40, 6.40, 2.31, 1.33, 1.33])  #For lam=0.40
lambdas = np.array([17.8, 6.40, 6.40, 2.31])  #For lam=0.40

def RMS(signal):
    return np.sqrt(np.mean(signal**2))


def read_data(path_data, added_SNR): 

    #Import labels (coeff of KL of the field)
    labels_path = path_data + '/samples_h1_60.csv'
    labels = np.genfromtxt(labels_path, delimiter=',', dtype=float)

    # Seleziona solo le prime 4 colonne
    labels = labels[:, :n_params]

    # scaling_factors = np.array([5.93, 4.32, 4.32, 3.15, 2.57, 2.57])  # Peso per ogni elemento del label
    # scaling_factors = np.array([17.8, 6.40, 6.40, 2.31, 1.33, 1.33])
    # scaled_labels = labels * scaling_factors  # Moltiplicazione elemento per elemento

    #Import simulation data from sensors
    sensors_path = path_data + '/sensorsdata_h1_60.csv'
    sensors_data = np.genfromtxt(sensors_path, delimiter=',', dtype=float)

    N_ist = len(labels)  

    # Creiamo la struttura per i segnali
    X = sensors_data.copy()  # Prendi direttamente i dati dai sensori
    X_noise = np.zeros_like(X)  # Stessa dimensione di X

    if path_data == path_data_train:

        #Apply noise
        for i in range(N_ist):
            rms_signal = np.sqrt(np.mean(X[i, :] ** 2))  
            dev_std = rms_signal / np.sqrt(added_SNR)  
            noise = st.norm.rvs(0, dev_std, size=X.shape[1])  
            X_noise[i, :] = X[i, :] + noise  

        # Calcola e salva le statistiche per la normalizzazione
        data_mean = np.mean(X_noise, axis=0)
        data_std = np.std(X_noise, axis=0)

        np.save(path_restore + '/data_mean.npy', data_mean)
        np.save(path_restore + '/data_std.npy', data_std)

    else:

        #Apply noise
        for i in range(N_ist):
            rms_signal = np.sqrt(np.mean(X[i, :] ** 2))  
            dev_std = rms_signal / np.sqrt(added_SNR)  
            noise = st.norm.rvs(0, dev_std, size=X.shape[1])  
            X_noise[i, :] = X[i, :] + noise  

        # Load mean and std_dev used to normalize training set
        data_mean = np.load(path_restore + '/data_mean.npy')
        data_std = np.load(path_restore + '/data_std.npy')

    # Normalizzazione sicura: evitare divisioni per zero
    data_std[data_std == 0] = 1  # Evita divisioni per 0
    X_noise = (X_noise - data_mean) / data_std

    return X_noise, labels, N_ist






"""
## Create a sampling layer
"""

class Sampling(layers.Layer):
    """Uses (z_mean, z_log_var) to sample z, the vector encoding a digit."""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.seed_generator = keras.random.SeedGenerator(1337)

    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = ops.shape(z_mean)[0]
        dim = ops.shape(z_mean)[1]
        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)
        return z_mean + ops.exp(0.5 * z_log_var) * epsilon





latent_dim = 8

# Hyperparameters
validation_split = 0.20
batch_size = 32
n_epochs = 250
early_stop_epochs=25
initial_lr = 1e-3
decay_length = 0.8
ratio_to_stop = 0.05



filter_1      = 32;   filter_2      = 64;   filter_3      = 32
kernel_size_1 = 3;   kernel_size_2 =  2;   kernel_size_3 = 2
neurons_4 = 32
neurons_5 = 16
attivaz_conv = 'tanh'
attivaz_mlp = 'tanh'
k_reg = 1e-3
b_reg = 1e-3
rate_drop = 0.3 #0.2

"""
## Build the encoder 
"""


encoder_inputs = layers.Input(shape=(seq_len,), name='Convolutional_inputs')

# Reshape per trasformare il vettore di 25 elementi in una griglia 3x3
x = layers.Reshape((int(np.sqrt(seq_len)), int(np.sqrt(seq_len)), 1))(encoder_inputs)  # 5x5 è la forma della griglia, 1 è il numero di canali

x = layers.Conv2D(filters=filter_1, kernel_size=(kernel_size_1, kernel_size_1), kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=None, padding='same', name='Conv_1')(x)
x = layers.BatchNormalization()(x)  # Normalizzazione del batch
x = layers.Activation('tanh')(x)  # Applica l'attivazione dopo la BatchNorm
x = layers.Dropout(rate=rate_drop)(x) 

# Secondo layer convoluzionale 2D
x = layers.Conv2D(filters=filter_2, kernel_size=(kernel_size_2, kernel_size_2), kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=None, padding='same', name='Conv_2')(x)
x = layers.BatchNormalization()(x)  # Normalizzazione del batch
x = layers.Activation('tanh')(x)  # Applica l'attivazione dopo la BatchNorm
x = layers.Dropout(rate=rate_drop)(x) 

# Terzo layer convoluzionale 2D
x = layers.Conv2D(filters=filter_3, kernel_size=(kernel_size_3, kernel_size_3), kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=None, padding='same', name='Conv_3')(x)
x = layers.BatchNormalization()(x)  # Normalizzazione del batch
x = layers.Activation('tanh')(x)  # Applica l'attivazione dopo la BatchNorm
x = layers.Dropout(rate=rate_drop)(x) 

# Flatten dei dati per connettersi ai layer fully connected
x = layers.Flatten()(x)

# Dense layers per l'encoder
x = layers.Dense(units=neurons_4, activation=None, kernel_regularizer=regularizers.l2(k_reg), 
                 bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(x)
x = layers.BatchNormalization()(x)  # Normalizzazione del batch
x = layers.Activation('relu')(x)  # Applica l'attivazione dopo la BatchNorm
x = layers.Dropout(rate=rate_drop)(x) 
# x = layers.Dense(units=neurons_5, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
#                  bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)

# Layer per la parte di variabili latenti (VAE)
z_mean = layers.Dense(latent_dim, activation=None, name='z_mean')(x)
z_log_var = layers.Dense(latent_dim, activation=None, name='z_log_var')(x)

# Sampling della variabile latente
z = Sampling()([z_mean, z_log_var])

# Modello Encoder
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
encoder.summary()





"""
## Build the decoder 
"""

# Input per il decoder (variabile latente)
latent_inputs = layers.Input(shape=(latent_dim,), name='Latent_inputs')

# Espansione del vettore latente in una forma adatta per il decoder (Dense + Reshape)
x = layers.Dense(units=neurons_4, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
                 bias_regularizer=regularizers.l2(b_reg), name='Dense_1_decoder')(latent_inputs)
x = layers.Dense(units=6*6*filter_3, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
                 bias_regularizer=regularizers.l2(b_reg), name='Dense_2_decoder')(x)

# Reshape per ottenere una griglia 
# x = layers.Reshape((int(np.sqrt(neurons_5)), int(np.sqrt(neurons_5)), 1))(x)
x = layers.Reshape((int(np.sqrt(seq_len)), int(np.sqrt(seq_len)), filter_3))(x)

# Primo layer di convoluzione trasposta
x = layers.Conv2DTranspose(filters=filter_2, kernel_size=(kernel_size_3, kernel_size_3), padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=None, name='Conv2DTranspose_1')(x)
x = layers.BatchNormalization()(x)  # Normalizzazione del batch
x = layers.Activation('relu')(x)  # Applica l'attivazione dopo la BatchNorm
x = layers.Dropout(rate=rate_drop)(x) 

# Secondo layer di convoluzione trasposta
x = layers.Conv2DTranspose(filters=filter_1, kernel_size=(kernel_size_2, kernel_size_2), padding='same', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), activation=None, name='Conv2DTranspose_2')(x)
x = layers.BatchNormalization()(x)  # Normalizzazione del batch
x = layers.Activation('relu')(x)  # Applica l'attivazione dopo la BatchNorm
x = layers.Dropout(rate=rate_drop)(x) 

# Terzo layer di convoluzione trasposta
x = layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), activation=None, padding='same', bias_regularizer=regularizers.l2(b_reg), name='Conv2DTranspose_3')(x)
x = layers.BatchNormalization()(x)  # Normalizzazione del batch
x = layers.Activation('relu')(x)  # Applica l'attivazione dopo la BatchNorm
x = layers.Dropout(rate=rate_drop)(x) 

# Flatten per convertire il risultato in un vettore
x = layers.Flatten()(x)

# Ultimo layer denso per ottenere un vettore di dimensione seq_len
decoder_outputs = layers.Dense(seq_len, activation=None, name='Final_output')(x)


# Creazione del modello del decoder
decoder = keras.Model(latent_inputs, decoder_outputs, name="Decoder")
decoder.summary()



"""
## Build the Predictor
"""

latent_inputs_predictor = layers.Input(shape=(latent_dim,), name='Latent_inputs')

# x = layers.Dense(units=32, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(latent_inputs_predictor)
# x = layers.Dropout(rate=rate_drop)(x) 
# # x = layers.Dense(units=128, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)
# x = layers.Dense(units=64, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3')(x)
# x = layers.Dropout(rate=rate_drop)(x) 
# x = layers.Dense(units=32, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_4')(x)
# x = layers.Dropout(rate=rate_drop)(x) 
# # Layer di output del predictor con attivazione lineare
# Dense_output = layers.Dense(n_params, activation='linear', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3_linear')(x)

x = layers.Dense(units=64, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(latent_inputs_predictor)
x = layers.Dropout(rate=rate_drop)(x)
x = layers.Dense(units=32, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)
# Layer di output del classificatore con attivazione lineare
Dense_output = layers.Dense(n_params, activation='linear', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3_linear')(x)


# Definisci il modello
predictor = keras.Model(latent_inputs_predictor, Dense_output, name='Predictor')
predictor.summary()



# # Parametri
# seq_len = 25  # Numero di elementi nell'input (griglia 5x5)
# latent_dim = 4  # Dimensione della variabile latente (può essere modificata)
# neurons_1 = 128  # Numero di neuroni nel primo layer fully connected
# neurons_2 = 64   # Numero di neuroni nel secondo layer fully connected
# neurons_3 = 32   # Numero di neuroni nel terzo layer fully connected
# k_reg = 1e-3     # Regularization per i pesi
# b_reg = 1e-3     # Regularization per i bias
# attivaz_mlp = 'elu'  # Funzione di attivazione

# # Encoder: Input di dimensione (25,) => griglia di sensori (5x5)
# encoder_inputs = layers.Input(shape=(seq_len,), name='Convolutional_inputs')

# # Primo layer fully connected
# x = layers.Dense(units=neurons_2, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
#                  bias_regularizer=regularizers.l2(b_reg), name='Dense_1_encoder')(encoder_inputs)
# x = layers.BatchNormalization()(x)
# # Secondo layer fully connected
# x = layers.Dense(units=neurons_1, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
#                  bias_regularizer=regularizers.l2(b_reg), name='Dense_2_encoder')(x)
# x = layers.BatchNormalization()(x)

# # Terzo layer fully connected
# x = layers.Dense(units=neurons_2, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
#                  bias_regularizer=regularizers.l2(b_reg), name='Dense_3_encoder')(x)
# x = layers.BatchNormalization()(x)

# x = layers.Dense(units=neurons_3, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
#                  bias_regularizer=regularizers.l2(b_reg), name='Dense_4_encoder')(x)
# x = layers.BatchNormalization()(x)

# # Variabili latenti (media e log varianza per il VAE)
# z_mean = layers.Dense(latent_dim, activation=None, name='z_mean')(x)
# z_log_var = layers.Dense(latent_dim, activation=None, name='z_log_var')(x)

# # Campionamento della variabile latente (condivisione della stessa variabile)
# z = Sampling()([z_mean, z_log_var])

# # Creazione del modello Encoder
# encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
# encoder.summary()




# # Decoder: Input dalla variabile latente
# latent_inputs = layers.Input(shape=(latent_dim,), name='Latent_inputs')

# # Primo layer denso del decoder
# x = layers.Dense(units=neurons_3, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
#                  bias_regularizer=regularizers.l2(b_reg), name='Dense_1_decoder')(latent_inputs)
# x = layers.BatchNormalization()(x)

# # Secondo layer denso del decoder
# x = layers.Dense(units=neurons_2, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
#                  bias_regularizer=regularizers.l2(b_reg), name='Dense_2_decoder')(x)
# x = layers.BatchNormalization()(x)

# # Terzo layer denso del decoder
# x = layers.Dense(units=neurons_1, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
#                  bias_regularizer=regularizers.l2(b_reg), name='Dense_3_decoder')(x)
# x = layers.BatchNormalization()(x)

# x = layers.Dense(units=neurons_2, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), 
#                  bias_regularizer=regularizers.l2(b_reg), name='Dense_3_encoder')(x)
# x = layers.BatchNormalization()(x)

# # Layer finale per ricostruire il vettore di output (dimensione seq_len)
# decoder_outputs = layers.Dense(seq_len, activation=None, name='Final_output')(x)

# # Creazione del modello Decoder
# decoder = keras.Model(latent_inputs, decoder_outputs, name="Decoder")
# decoder.summary()



# latent_inputs_predictor = layers.Input(shape=(latent_dim,), name='Latent_inputs')
# x = layers.Dense(units=64, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_1')(latent_inputs_predictor)
# x = layers.BatchNormalization()(x)
# x = layers.Dense(units=128, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_2')(x)
# x = layers.BatchNormalization()(x)
# x = layers.Dense(units=32, activation=attivaz_mlp, kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3')(x)
# x = layers.BatchNormalization()(x)
# # Layer di output del predictor con attivazione lineare
# Dense_output = layers.Dense(n_params, activation='linear', kernel_regularizer=regularizers.l2(k_reg), bias_regularizer=regularizers.l2(b_reg), name='Dense_3_linear')(x)

# # Definisci il modello
# predictor = keras.Model(latent_inputs_predictor, Dense_output, name='Predictor')
# predictor.summary()







"""
## Define the VAE class
"""

class VAE(keras.Model):
    def __init__(self, encoder, decoder, predictor,**kwargs):
        super().__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.predictor = predictor
        self.total_loss_tracker = keras.metrics.Mean(name="total_loss")
        self.reconstruction_loss_tracker = keras.metrics.Mean(name="reconstruction_loss")
        self.kl_loss_tracker = keras.metrics.Mean(name="kl_loss")
        self.predictor_loss_tracker = keras.metrics.Mean(name="predictor_loss")

    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
            self.predictor_loss_tracker,
        ]

    def prediction_loss(self, true_labels, predictor_preds):

        true_labels = tf.cast(true_labels, tf.float32)
        predictor_preds = tf.cast(predictor_preds, tf.float32)

        # Calcola la differenza quadrata tra i valori reali e quelli predetti
        diff = true_labels - predictor_preds
        squared_diff = tf.square(diff)  # differenza al quadrato
        
        # Moltiplica la differenza al quadrato per il vettore dei pesi
        weighted_loss = squared_diff * lambdas  # Moltiplicazione element-wise
        
        # Somma lungo la dimensione delle features (per ogni esempio nel batch)
        loss_per_sample = tf.reduce_sum(weighted_loss, axis=1)

        loss_per_batch = tf.reduce_mean(loss_per_sample)
        
        return loss_per_batch
    

    def train_step(self, data):

        observations, true_labels = data


        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(observations)

            reconstruction = self.decoder(z)

            predictor_preds = self.predictor(z)

            reconstruction_loss = ops.mean(
                keras.losses.mean_squared_error(observations, reconstruction)
            )
            
            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))
            kl_loss = ops.mean(kl_loss)

            # predictor_loss = keras.losses.mean_squared_error(predictor_preds, true_labels)
            # predictor_loss = tf.reduce_mean(predictor_loss)
            # predictor_loss = tf.cast(predictor_loss, tf.float32)

            # Prediction loss
            predictor_loss = self.prediction_loss(true_labels, predictor_preds)

            alfa = 10.0
            beta = 1.0
            gamma = 0.30
            total_loss = alfa * reconstruction_loss + beta * kl_loss + gamma * predictor_loss 


        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))

        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        self.predictor_loss_tracker.update_state(predictor_loss)
        return {
            "loss": self.total_loss_tracker.result(),
            "reconstruction_loss": self.reconstruction_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
            "predictor_loss": self.predictor_loss_tracker.result(),
        }
    
    
    def test_step(self, data):

        observations, true_labels = data
        
        z_mean, z_log_var, z = self.encoder(observations)
        reconstruction = self.decoder(z)
        predictor_preds = self.predictor(z)

        # Calcolo della perdita per il test
        reconstruction_loss = ops.mean(
            keras.losses.mean_squared_error(observations, reconstruction)
            )
        
        kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))
        kl_loss = ops.mean(kl_loss)

        # Prediction loss
        predictor_loss = self.prediction_loss(true_labels, predictor_preds)

        # predictor_loss = keras.losses.mean_squared_error(predictor_preds, true_labels)
        # predictor_loss = tf.reduce_mean(predictor_loss)
        # predictor_loss = tf.cast(predictor_loss, tf.float32)

        alfa = 10.0
        beta = 1.0
        gamma = 0.30
        total_loss = alfa * reconstruction_loss + beta * kl_loss + gamma * predictor_loss

        return {
            "loss": total_loss,
            "reconstruction_loss": reconstruction_loss,
            "kl_loss": kl_loss,
            "predictor_loss": predictor_loss,
        }
    
    
    def call(self, inputs):
        # Passaggio attraverso l'encoder
        z_mean, z_log_var, z = self.encoder(inputs)
        
        # Decodifica del campione z
        reconstructed = self.decoder(z)

        # Decodifica del campione z
        predicted = self.predictor(z)
        
        return reconstructed, predicted





"""
## Funzioni utili
"""

def plot_label_clusters_3d(vae, data, labels):
    # display a 3D plot of the digit classes in the latent space
    z_mean, _, _ = vae.encoder.predict(data, verbose=0)

    print(f"Forma di z_mean: {z_mean.shape}")
    print(f"Primi elementi di z_mean:\n{z_mean[0:4,:]}")

    if z_mean.shape[1] < 3:
        print("Attenzione: z_mean ha meno di 3 dimensioni. Potrebbe non essere possibile creare un grafico 3D.")
        return
    

    # Plot using nothing
    # second_coeff = labels[:,1]

    # # Crea il grafico
    # fig = plt.figure(figsize=(12, 10))
    # ax = fig.add_subplot(111, projection='3d')

    # # Colora i punti in base ai damage levels della classe 1
    # scatter = ax.scatter(z_mean[:, 0], z_mean[:, 1], z_mean[:, 2],
    #                     c=second_coeff, cmap='jet')
    # color_bar = fig.colorbar(scatter, ax=ax)
    # color_bar.set_label('Second Coeff.', fontsize=16)

    # # Setta le etichette degli assi e il titolo
    # ax.set_xlabel("z_mean[0]", fontsize=14)
    # ax.set_ylabel("z_mean[1]", fontsize=14)
    # ax.set_zlabel("z_mean[2]", fontsize=14)
    # plt.suptitle(f'Colored respect the second coeff', fontsize=16)

    # # Salva e mostra il grafico
    # plt.savefig(os.path.join(output_dir, "latent_second_coeff_3d.png"))
    # plt.show()

    # # Plot using MDS
    # mds = MDS(n_components=3)
    # z_mds = mds.fit_transform(z_mean)

    # fig = plt.figure(figsize=(12, 10))
    # ax = fig.add_subplot(111, projection='3d')
    # scatter = ax.scatter(z_mds[:, 0], z_mds[:, 1], z_mds[:, 2], c=labels, cmap='viridis')
    # color_bar = fig.colorbar(scatter, ax=ax)
    # color_bar.set_label('Classi')
    # ax.set_xlabel("MDS[0]")
    # ax.set_ylabel("MDS[1]")
    # ax.set_zlabel("MDS[2]")
    # plt.suptitle(f'Grouped by damage class in 3D latent space using MDS', fontsize=16)
    # plt.savefig(os.path.join(output_dir, "label_clusters_mds_3d.png"))
    # plt.show()

    # # Plot using TSNE  (in teoria serve più che altro se hai input categoriale)
    # tsne = TSNE(n_components=3)
    # z_tsne = tsne.fit_transform(z_mean)

    # fig = plt.figure(figsize=(12, 10))
    # ax = fig.add_subplot(111, projection='3d')
    # scatter = ax.scatter(z_tsne[:, 0], z_tsne[:, 1], z_tsne[:, 2], c=labels, cmap='viridis')
    # color_bar = fig.colorbar(scatter, ax=ax)
    # color_bar.set_label('Classi')
    # ax.set_xlabel("TSNE[0]")
    # ax.set_ylabel("TSNE[1]")
    # ax.set_zlabel("TSNE[2]")
    # plt.suptitle(f'Grouped by damage class in 3D latent space using TSNE', fontsize=16)
    # plt.savefig(os.path.join(output_dir, "label_clusters_tsne_3d.png"))
    # plt.show()

    # Plot using PCA
    first_coeff = labels[:,0]

    # Esegue la PCA 
    pca = PCA(n_components=3)
    z_pca = pca.fit_transform(z_mean)

    # # Crea il grafico
    # fig = plt.figure(figsize=(12, 10))
    # ax = fig.add_subplot(111, projection='3d')

    # # Colora i punti in base ai damage levels della classe 1
    # scatter = ax.scatter(z_pca[:, 0], z_pca[:, 1], z_pca[:, 2],
    #                     c=first_coeff, cmap='jet')
    # color_bar = fig.colorbar(scatter, ax=ax)
    # color_bar.set_label('First Coeff.', fontsize=16)

    # # Setta le etichette degli assi e il titolo
    # ax.set_xlabel("PCA[0]", fontsize=14)
    # ax.set_ylabel("PCA[1]", fontsize=14)
    # ax.set_zlabel("PCA[2]", fontsize=14)
    # plt.suptitle(f'Colored respect the first coeff', fontsize=16)

    # # Salva e mostra il grafico
    # plt.savefig(os.path.join(output_dir, "latent_first_coeff_pca_3d.png"))
    # plt.show()

    # Crea il grafico con 9 subplot
    fig, axes = plt.subplots(2, 2, figsize=(15, 15), subplot_kw={'projection': '3d'})

    # Loop per generare i 4 subplot con colori diversi
    for i, ax in enumerate(axes.flat):
        scatter = ax.scatter(z_pca[:, 0], z_pca[:, 1], z_pca[:, 2],
                            c=labels[:, i], cmap='jet')
        color_bar = fig.colorbar(scatter, ax=ax, shrink=0.6)
        color_bar.set_label(f'Coeff {i+1}', fontsize=12)

        # Setta le etichette degli assi e il titolo
        ax.set_xlabel("PCA[0]", fontsize=10)
        ax.set_ylabel("PCA[1]", fontsize=10)
        ax.set_zlabel("PCA[2]", fontsize=10)
        ax.set_title(f'Color based on Coeff {i+1}', fontsize=12)

    # Titolo generale del grafico
    plt.suptitle('3D PCA Colored by Different Coefficients', fontsize=16)

    # Salva e mostra il grafico
    output_dir = "output_VAE_for_MCMC"
    plt.savefig(os.path.join(output_dir, "latent_coeff_pca_3d_subplots.png"))
    plt.show()








train_or_predict = 1   # 1: training, 0: predict                                       


if train_or_predict:

    """
    ## Model training
    """

    X_train, labels_train, N_ist = read_data(path_data_train, 100)

    print(f"Forma di X_train: {X_train.shape}")

    print(f"Forma di labels: {labels_train.shape}")

    # print("Prime 2 righe di X_train:")
    # print(X_train[:2])

    # Separare i dati in training e validation set
    train_observations, val_observations, train_labels, val_labels = train_test_split(X_train, labels_train, test_size=validation_split, shuffle=True)

    # Creare dataset TensorFlow per il training
    train_dataset = tf.data.Dataset.from_tensor_slices((train_observations, train_labels))
    train_dataset = train_dataset.batch(batch_size)

    # Creare dataset TensorFlow per la validazione
    val_dataset = tf.data.Dataset.from_tensor_slices((val_observations, val_labels))
    val_dataset = val_dataset.batch(batch_size)

    vae = VAE(encoder, decoder, predictor)

    vae.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist*(1-validation_split)/batch_size), alpha=ratio_to_stop)))

    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stop_epochs, restore_best_weights=True)


    # Allenamento del modello
    history = vae.fit(train_dataset, epochs=n_epochs, validation_data=val_dataset, batch_size=batch_size, verbose=2, callbacks=[early_stop])


    # Salva lo storico dell'addestramento in formato pickle
    hist = pd.DataFrame(history.history)  # Converti history.history (dati storici dell'addestramento) in un DataFrame di pandas
    hist['epoch'] = history.epoch  # Aggiungi una colonna per le epoche. history.epoch è una lista che contiene i numeri delle epoche per cui sono stati registrati i dati.

    # Salva il DataFrame
    try:
        hist.to_pickle(os.path.join(path_save, 'hist_VAE_for_MCMC.pkl'))   #Salva il DataFrame hist in un file con formato pickle.
        print(f"Storico salvato in {os.path.join(path_save, 'hist_VAE_for_MCMC.pkl')}")
    except Exception as e:
        print(f"Errore durante il salvataggio dello storico: {e}")

    # Salva il modello
    try:
        vae.save(os.path.join(path_save, 'model_VAE_for_MCMC.keras'))   # Salva il modello vae addestrato in formato Keras
        print(f"Modello salvato in {os.path.join(path_save, 'model_VAE_for_MCMC.keras')}")
    except Exception as e:
        print(f"Errore durante il salvataggio del modello: {e}")

    # Salva i pesi

    vae.build(input_shape=(None, seq_len)) 

    vae.save_weights('./models/VAE_for_MCMC.weights.h5')
    print(f"Weights saved in {os.path.join(path_save, 'VAE_for_MCMC.weights.h5')}")


    """
    ## Output
    """

    # Crea la cartella se non esiste
    output_dir = "output_VAE_for_MCMC"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Plot combinato per la training loss e la validation loss
    plt.figure(figsize=(15, 5))  # Dimensioni del plot
    plt.plot(history.history["loss"], label="Training Loss", color='blue')
    plt.plot(history.history["val_loss"], label="Validation Loss", color='orange')
    plt.title("Training and Validation Loss")
    plt.ylabel("Loss")
    plt.xlabel("Epoch")
    plt.legend(loc="upper right")
    plt.grid(True)
    plt.savefig(os.path.join(output_dir, "losses.png"))
    plt.show()
    plt.close()

    # plot_label_clusters(vae, observations_normalized , damage_class_labels)
    plot_label_clusters_3d(vae, X_train , labels_train)


else:

    """
    ## Predict
    """

    # Caricamento dei dati di test
    X_test, labels_test, N_ist_test = read_data(path_data_test, 100)

    print(f"Forma di X_test: {X_test.shape}")

    # Creazione dell'istanza VAE
    vae = VAE(encoder, decoder, predictor)
    vae.compile(optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=initial_lr, decay_steps=int(decay_length*n_epochs*N_ist_test*(1-validation_split)/batch_size), alpha=ratio_to_stop)))

    # Caricamento dei pesi salvati
    vae.build(input_shape=(None, seq_len))

    vae.load_weights('./models/VAE_for_MCMC.weights.h5')    


    output_dir = "output_VAE_for_MCMC"
    # plot_label_clusters(vae, observations_normalized , damage_class_labels)
    plot_label_clusters_3d(vae, X_test , labels_test)


    # Ricostruzione dei dati di test
    X_test_reconstructed, X_test_labels = vae.predict(X_test)

    # Caricamento della cronologia dell'addestramento
    hist = pd.read_pickle(path_save + 'hist_VAE_for_MCMC.pkl')


    """
    ## Creazione latent dataset di train e test
    """

    X_train, labels_train, N_ist_train = read_data(path_data_train, 100)
    X_test, labels_test, N_ist_test = read_data(path_data_test, 100)

    # Usa l'encoder per ottenere i vettori latenti
    _, _, z_train = vae.encoder.predict(X_train)
    _, _, z_test = vae.encoder.predict(X_test)
    
    # Convertili in un dataframe per facilità di salvataggio
    latent_space_train_df = pd.DataFrame(z_train)
    latent_space_test_df = pd.DataFrame(z_test)
    
    # Crea il percorso completo del file
    full_path_train = os.path.join(output_dir, "z_train.csv")
    full_path_test = os.path.join(output_dir, "z_test.csv")
    
    # Salva il dataframe in formato CSV
    latent_space_train_df.to_csv(full_path_train, index=False)
    latent_space_test_df.to_csv(full_path_test, index=False)
    


    """
    ## Creazione latent dataset di train e test 2 per mcmc_2
    """

    X_train, labels_train, N_ist_train = read_data(path_data_train, 100)
    X_test, labels_test, N_ist_test = read_data(path_data_test, 100)

    # Usa l'encoder per ottenere i vettori latenti (media e varianza)
    z_mean_train, z_log_var_train, _ = vae.encoder.predict(X_train)
    z_mean_test, z_log_var_test, _ = vae.encoder.predict(X_test)

    # Concatena media e varianza lungo l'asse delle colonne
    # Questo creerà un array con la media seguita dalla varianza per ogni dimensione latente
    z_train_combined = np.concatenate([z_mean_train, z_log_var_train], axis=1)
    z_test_combined = np.concatenate([z_mean_test, z_log_var_test], axis=1)
    
    # Convertili in un dataframe per facilità di salvataggio
    # Per chiarezza, nominiamo le colonne come "mean_0", "mean_1", ..., "var_0", "var_1", ...
    columns_train = [f"mean_{i}" for i in range(z_mean_train.shape[1])] + [f"var_{i}" for i in range(z_log_var_train.shape[1])]
    latent_space_train_df = pd.DataFrame(z_train_combined, columns=columns_train)

    columns_test = [f"mean_{i}" for i in range(z_mean_test.shape[1])] + [f"var_{i}" for i in range(z_log_var_test.shape[1])]
    latent_space_test_df = pd.DataFrame(z_test_combined, columns=columns_test)

    # Crea il percorso completo del file
    full_path_train = os.path.join(output_dir, "z_train2.csv")
    full_path_test = os.path.join(output_dir, "z_test2.csv")

    # Salva il dataframe in formato CSV
    latent_space_train_df.to_csv(full_path_train, index=False)
    latent_space_test_df.to_csv(full_path_test, index=False)